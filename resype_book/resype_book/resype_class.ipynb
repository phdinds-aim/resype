{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded4b7ce",
   "metadata": {},
   "source": [
    "# ReSyPE Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bc4618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:15:54.516615Z",
     "start_time": "2021-09-23T02:15:53.187035Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "import jdc\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff35c9a",
   "metadata": {},
   "source": [
    "## ReSyPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbcf261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resype:\n",
    "    \"\"\"\n",
    "    Resype implements a machine learning framework for recommender systems.\n",
    "            Parameters:\n",
    "                    transaction_list (pandas.DataFrame): Dataframe with columns user_id, item_id, rating in the form\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 1     | 4    |\n",
    "                        \n",
    "            Final outputs:\n",
    "                    recommendations (pandas.DataFrame): Dataframe with columns user_id, item_id, score\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 3     | 2    |                    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_list):\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "                    transaction_list (pandas.DataFrame): Dataframe with columns user_id, item_id, rating in the form\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 1     | 4    |        \n",
    "        \"\"\"\n",
    "        self.transaction_list = transaction_list\n",
    "        self.users_clustered = False # whether the users were clustered\n",
    "        self.items_clustered = False # whether the items were clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d923a3d",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feca9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def construct_utility_matrix(self):\n",
    "    self.utility_matrix = transaction_list.pivot(index='user_id', columns='item_id', values='rating') # utility matrix    \n",
    "    return self.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "879d84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24095</th>\n",
       "      <td>167</td>\n",
       "      <td>1080</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43152</th>\n",
       "      <td>288</td>\n",
       "      <td>56339</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32510</th>\n",
       "      <td>221</td>\n",
       "      <td>5945</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87851</th>\n",
       "      <td>567</td>\n",
       "      <td>5502</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88663</th>\n",
       "      <td>572</td>\n",
       "      <td>3011</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "24095      167     1080     3.5\n",
       "43152      288    56339     3.5\n",
       "32510      221     5945     4.5\n",
       "87851      567     5502     2.0\n",
       "88663      572     3011     3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_list = pd.read_csv(\"sample_data/ratings.csv\")[['userId', 'movieId', 'rating']]\n",
    "transaction_list = transaction_list.sample(100)\n",
    "transaction_list.columns = [\"user_id\", 'item_id', 'rating']\n",
    "\n",
    "re = Resype(transaction_list)\n",
    "re.transaction_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dffb33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>6</th>\n",
       "      <th>17</th>\n",
       "      <th>34</th>\n",
       "      <th>50</th>\n",
       "      <th>150</th>\n",
       "      <th>170</th>\n",
       "      <th>186</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>308</th>\n",
       "      <th>...</th>\n",
       "      <th>91529</th>\n",
       "      <th>92259</th>\n",
       "      <th>102123</th>\n",
       "      <th>111362</th>\n",
       "      <th>111844</th>\n",
       "      <th>112556</th>\n",
       "      <th>134170</th>\n",
       "      <th>142488</th>\n",
       "      <th>152081</th>\n",
       "      <th>165551</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  6       17      34      50      150     170     186     260     \\\n",
       "user_id                                                                   \n",
       "11          NaN     NaN     NaN     NaN     NaN     4.0     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "21          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "33          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "41          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "600         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "606         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  296     308     ...  91529   92259   102123  111362  111844  112556  \\\n",
       "user_id                  ...                                                   \n",
       "11          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "21          NaN     NaN  ...     NaN     NaN     NaN     NaN     3.5     NaN   \n",
       "33          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "41          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "600         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "606         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     4.0     NaN     NaN   \n",
       "\n",
       "item_id  134170  142488  152081  165551  \n",
       "user_id                                  \n",
       "11          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "21          NaN     NaN     NaN     NaN  \n",
       "33          NaN     NaN     NaN     NaN  \n",
       "41          NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "600         NaN     NaN     NaN     NaN  \n",
       "603         NaN     NaN     NaN     NaN  \n",
       "606         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[83 rows x 98 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.construct_utility_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a2e57",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1b39f",
   "metadata": {},
   "source": [
    "#### Preprocess Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7dc04c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:18.560671Z",
     "start_time": "2021-09-23T02:16:18.525163Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def mean_center_utilmat(self, axis=1, fillna=True, fill_val=None):\n",
    "    \"\"\"Gets the mean-centered utility matrix\n",
    "\n",
    "    Parameters:\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        axis (int) : The axis along mean is evaluated, \n",
    "            {0/'index', 1/'columns'}, default 1\n",
    "        fillna (bool) : Indicates whether missing/null values are to be filled\n",
    "        fill_val (None/float) : Value to be used to fill null values when \n",
    "            fillna==True, default None\n",
    "\n",
    "    Returns:\n",
    "        U (DataFrame): mean-centered utility matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # variables\n",
    "    U = self.utility_matrix\n",
    "    \n",
    "    mean_centered = U.sub(U.mean(axis=axis), axis=1-axis)\n",
    "    if fillna:\n",
    "        if fill_val is not None:\n",
    "            return mean_centered.fillna(fill_val)\n",
    "        else:\n",
    "            return mean_centered.fillna(0)\n",
    "    else:\n",
    "        return mean_centered\n",
    "\n",
    "\n",
    "def split_utilmat_label_features(self, label_index, axis=1):\n",
    "    \"\"\"Splits utility matrix into label (column/row where ratings are predicted) \n",
    "    and features (columns/rows to be used as input in the model)\n",
    "\n",
    "    Parameters:\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        label_index : column name or index corresponding to  item ratings (column)\n",
    "            or user ratings (row) to be predicted\n",
    "        axis (int) : The axis along the utility matrix is split, \n",
    "            {0/'index', 1/'columns'}, default 1\n",
    "\n",
    "    Returns:\n",
    "        label_df (DataFrame) : contains the column/row to be predicted\n",
    "        feature_df (DataFrame) : contains the features   \n",
    "    \"\"\"\n",
    "    \n",
    "    # VARIABLES\n",
    "    U = self.utility_matrix\n",
    "    \n",
    "    if axis == 1:\n",
    "        label_col = U.columns[U.columns == label_index]\n",
    "        feature_col = U.columns[~(U.columns == label_index)]\n",
    "        label_df = U.loc[:, label_col]\n",
    "        feature_df = U.loc[:, feature_col]\n",
    "    elif axis == 0:\n",
    "        label_row = U.index[U.index == label_index]\n",
    "        feature_row = U.index[~(U.index == label_index)]\n",
    "        label_df = U.loc[label_row, :]\n",
    "        feature_df = U.loc[feature_row, :]\n",
    "\n",
    "    return label_df, feature_df\n",
    "\n",
    "\n",
    "def known_missing_split_1d(label_data, feature_data, split_axis=1,\n",
    "                           missing_val_filled=False, fill_val=None):\n",
    "    \"\"\"Returns index of the dataset corresponding to known and missing ratings\n",
    "    in the label data (row or column to be predicted)\n",
    "\n",
    "    Parameters:\n",
    "        label_df (DataFrame) : contains the column/row to be predicted\n",
    "        feature_df (DataFrame) : contains the features  \n",
    "        split_axis (int) : The axis along the utility matrix is split, \n",
    "            {0/'index', 1/'columns'}, default 1\n",
    "        missing_val_filled (bool) : Indicates whether missing/null values \n",
    "            in the label/feature data were filled\n",
    "        fill_val (None/float) : Value used to fill the null values when \n",
    "            missing_val_filled==True, default None            \n",
    "\n",
    "    Returns:\n",
    "        X_known.index : index corresponding to known ratings\n",
    "        X_missing.index : index corresponding to missing/unknown ratings\n",
    "    \"\"\"    \n",
    "    if missing_val_filled:\n",
    "        if fill_val is None:\n",
    "            missing_vals = (label_data == 0).values.flatten()\n",
    "        else:\n",
    "            missing_vals = (label_data == fill_val).values.flatten()\n",
    "    else:\n",
    "        missing_vals = label_data.isnull().values.flatten()\n",
    "    if split_axis == 1:\n",
    "        X_missing = feature_data.loc[missing_vals, :]\n",
    "        X_known = feature_data.loc[~missing_vals, :]\n",
    "    elif split_axis == 0:\n",
    "        X_missing = feature_data.loc[:, missing_vals]\n",
    "        X_known = feature_data.loc[:, ~missing_vals]\n",
    "    else:\n",
    "        X_missing = feature_data.loc[missing_vals, :]\n",
    "        X_known = feature_data.loc[~missing_vals, :]\n",
    "\n",
    "    return X_known.index, X_missing.index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cbdda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def known_missing_split_U(U, split_axis=1, missing_val_filled=False,\n",
    "                          fill_val=None):\n",
    "    \"\"\"Returns index of the dataset corresponding to known and missing ratings\n",
    "    in for the whole utility matrix\n",
    "\n",
    "    Parameters:\n",
    "        U (DataFrame) : utility matrix (rows are users, columns are items) \n",
    "        split_axis (int) : The axis along the utility matrix is split, \n",
    "            {0/'index', 1/'columns'}, default 1\n",
    "        missing_val_filled (bool) : Indicates whether missing/null values \n",
    "            in the label/feature data were filled\n",
    "        fill_val (None/float) : Value used to fill the null values when \n",
    "            missing_val_filled==True, default None            \n",
    "\n",
    "    Returns:\n",
    "        known_idx (dict): keys are the column name/index to be predicted, \n",
    "            values are index of the utility matrix that contains known values\n",
    "        missing_idx (dict): keys are the column name/index to be predicted, \n",
    "            values are index of the utility matrix that contains missing values\n",
    "    \"\"\"    \n",
    "    \n",
    "    if missing_val_filled:\n",
    "        if fill_val is None:\n",
    "            missing_val = 0\n",
    "        else:\n",
    "            missing_val = fill_val\n",
    "        if split_axis == 1:\n",
    "            known_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "        elif split_axis == 0:\n",
    "            known_idx = dict((U == missing_val).apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.T.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).apply(lambda x: np.array(x), axis=1).apply(\n",
    "                lambda x: U.T.index[np.argwhere(x).flatten()]))\n",
    "        else:\n",
    "            print('Invalid axis. Result for axis=1 is returned.')\n",
    "            known_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "    else:\n",
    "        if split_axis == 1:\n",
    "            known_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "        elif split_axis == 0:\n",
    "            train_idx = dict(U.isnull().apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.T.index[np.argwhere(~x).flatten()]))\n",
    "            test_idx = dict(U.isnull().apply(lambda x: np.array(x), axis=1).apply(\n",
    "                lambda x: U.T.index[np.argwhere(x).flatten()]))\n",
    "        else:\n",
    "            print('Invalid axis. Result for axis=1 is returned.')\n",
    "            known_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "\n",
    "    return known_idx, missing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17c88426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>6</th>\n",
       "      <th>17</th>\n",
       "      <th>34</th>\n",
       "      <th>50</th>\n",
       "      <th>150</th>\n",
       "      <th>170</th>\n",
       "      <th>186</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>308</th>\n",
       "      <th>...</th>\n",
       "      <th>91529</th>\n",
       "      <th>92259</th>\n",
       "      <th>102123</th>\n",
       "      <th>111362</th>\n",
       "      <th>111844</th>\n",
       "      <th>112556</th>\n",
       "      <th>134170</th>\n",
       "      <th>142488</th>\n",
       "      <th>152081</th>\n",
       "      <th>165551</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  6       17      34      50      150     170     186     260     \\\n",
       "user_id                                                                   \n",
       "11          NaN     NaN     NaN     NaN     NaN     4.0     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "21          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "33          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "41          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "600         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "606         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  296     308     ...  91529   92259   102123  111362  111844  112556  \\\n",
       "user_id                  ...                                                   \n",
       "11          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "21          NaN     NaN  ...     NaN     NaN     NaN     NaN     3.5     NaN   \n",
       "33          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "41          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "600         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "606         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     4.0     NaN     NaN   \n",
       "\n",
       "item_id  134170  142488  152081  165551  \n",
       "user_id                                  \n",
       "11          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "21          NaN     NaN     NaN     NaN  \n",
       "33          NaN     NaN     NaN     NaN  \n",
       "41          NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "600         NaN     NaN     NaN     NaN  \n",
       "603         NaN     NaN     NaN     NaN  \n",
       "606         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[83 rows x 98 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52a63bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>6</th>\n",
       "      <th>17</th>\n",
       "      <th>34</th>\n",
       "      <th>50</th>\n",
       "      <th>150</th>\n",
       "      <th>170</th>\n",
       "      <th>186</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>308</th>\n",
       "      <th>...</th>\n",
       "      <th>91529</th>\n",
       "      <th>92259</th>\n",
       "      <th>102123</th>\n",
       "      <th>111362</th>\n",
       "      <th>111844</th>\n",
       "      <th>112556</th>\n",
       "      <th>134170</th>\n",
       "      <th>142488</th>\n",
       "      <th>152081</th>\n",
       "      <th>165551</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  6       17      34      50      150     170     186     260     \\\n",
       "user_id                                                                   \n",
       "11          0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "20          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "600         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "603         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "606         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "608         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "610         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "item_id  296     308     ...  91529   92259   102123  111362  111844  112556  \\\n",
       "user_id                  ...                                                   \n",
       "11          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "20          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "600         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "603         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "606         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "608         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "610         0.0     0.0  ...     0.0     0.0     0.0     0.5     0.0     0.0   \n",
       "\n",
       "item_id  134170  142488  152081  165551  \n",
       "user_id                                  \n",
       "11          0.0     0.0     0.0     0.0  \n",
       "20          0.0     0.0     0.0     0.0  \n",
       "21          0.0     0.0     0.0     0.0  \n",
       "33          0.0     0.0     0.0     0.0  \n",
       "41          0.0     0.0     0.0     0.0  \n",
       "...         ...     ...     ...     ...  \n",
       "600         0.0     0.0     0.0     0.0  \n",
       "603         0.0     0.0     0.0     0.0  \n",
       "606         0.0     0.0     0.0     0.0  \n",
       "608         0.0     0.0     0.0     0.0  \n",
       "610         0.0     0.0     0.0     0.0  \n",
       "\n",
       "[83 rows x 98 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_df_mc = re.mean_center_utilmat(axis=1, fillna=True, fill_val=0)\n",
    "U_df_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2211a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_index, missing_index = known_missing_split_U(\n",
    "    U=U_df_mc, split_axis=1, missing_val_filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "add077c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:20.000940Z",
     "start_time": "2021-09-23T02:16:19.993558Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def nan_mask(p=0.2):\n",
    "    # VARS\n",
    "    U = self.utility_matrix\n",
    "    \n",
    "    mask = np.ones(np.shape(U))\n",
    "    random_index = np.random.choice(U.size, size=int(U.size*p), replace=False)\n",
    "    np.ravel(mask)[random_index] = np.nan\n",
    "    return U*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d85f773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:20.585119Z",
     "start_time": "2021-09-23T02:16:20.577003Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def gen_missing_ratings(U_df, p=0.2, n_masks=10):\n",
    "    cols = U_df.columns\n",
    "    idx = U_df.index\n",
    "    U_arr = U_df.values\n",
    "    masked_um = []\n",
    "    for n in range(n_masks):\n",
    "        masked_um.append(pd.DataFrame(nan_mask(U_arr, p=p),\n",
    "                                      columns=cols,\n",
    "                                      index=idx))\n",
    "    return masked_um"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a853e0",
   "metadata": {},
   "source": [
    "#### Non-clustered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5c9b625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:27.255608Z",
     "start_time": "2021-09-23T02:16:27.226208Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_models_itemwise(U, model, suffix='model'):\n",
    "    \"\"\"Initializes classifier/regressor per item to be predicted\n",
    "\n",
    "    Parameters:\n",
    "        model : model object to use to fit the data\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        suffix (str) : suffix for keys in output dictionary\n",
    "\n",
    "    Returns:\n",
    "        models (dict): dictionary of models, keys correspond to columns/items \n",
    "        in the utility matrix and values are the model objects\n",
    "    \"\"\"\n",
    "    models = {f'{item}{suffix}': model for item in U.columns}\n",
    "    return models\n",
    "\n",
    "\n",
    "def initialize_models_userwise(U, model, suffix='_model'):\n",
    "    \"\"\"Initializes classifier/regressor per user to be predicted\n",
    "\n",
    "    Parameters:\n",
    "        model : model object to use to fit the data\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        suffix (str) : suffix for keys in output dictionary\n",
    "\n",
    "    Returns:\n",
    "        models (dict): dictionary of models, keys correspond to the rows/users \n",
    "            in the utility matrix and values are the model objects\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {f'{user}{suffix}': model for user in U.index}\n",
    "    return models\n",
    "\n",
    "\n",
    "def eval_convergence_criterion(\n",
    "        pred_curr, pred_prev, stopping_criterion='mse',\n",
    "        mse_threshold=0.1, stdev_threshold=None,\n",
    "        scaled=False, scaling_method='max',\n",
    "        rating_min=None, rating_max=None):\n",
    "    \"\"\"\n",
    "    Evaluates whether the model training has converged\n",
    "\n",
    "    Parameters:\n",
    "        pred_curr (array) : array of predicted ratings from current iteration\n",
    "        pred_prev (array) : array of predicted ratings from previous iteration\n",
    "        stopping_criterion (str) : metric for evaluating convergence, \n",
    "            {mse/'mean squared error', stdev_abs/'standard deviation of \n",
    "            absolute difference'}, default 'mse'\n",
    "        mse_threshold (float) : threshold for stopping criterion when \n",
    "            'mse'is selected, default 0.1            \n",
    "        stdev_threshold (float) : threshold for stopping criterion when \n",
    "            'stdev_abs'is selected, default None\n",
    "        scaled (bool) : Indicates whether metric for stopping criterion is \n",
    "            to be scaled/normalized\n",
    "        scaling_method (str) : indicates method for scaling when scaled==True, \n",
    "            {max/'maximum rating', minmax/'maximum rating - minimum rating'},\n",
    "            default 'max'\n",
    "        rating_min (numeric) : minimum value of rating, default None\n",
    "        rating_max (numeric) : maximum value of rating, default None\n",
    "\n",
    "    Returns:\n",
    "        metric (float) : value of metric\n",
    "        stop_train (bool) : Indicates convergence (stop training when True)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if stopping_criterion == 'mse':\n",
    "        if mse_threshold is None:\n",
    "            print('Threshold for calculating MSE is not defined. '\n",
    "                  'Input threshold value.')\n",
    "        metric = mean_squared_error(pred_curr, pred_prev)\n",
    "\n",
    "        if scaled:\n",
    "            if scaling_method == 'max':\n",
    "                if rating_max is None:\n",
    "                    print('Scaled metric needs maximum possible value '\n",
    "                          'of rating.')\n",
    "                else:\n",
    "                    scaling_factor = rating_max\n",
    "            elif scaling_metho == 'minmax':\n",
    "                if (rating_max is None) or (rating_min is None):\n",
    "                    print(\n",
    "                        'Scaled metric needs maximum and minimum '\n",
    "                        'possible values of rating.')\n",
    "                else:\n",
    "                    scaling_factor = (rating_max - rating_min)\n",
    "            metric /= scaling_factor\n",
    "\n",
    "        stop_train = (metric <= mse_threshold)\n",
    "\n",
    "    elif stopping_criterion == 'stdev_abs':\n",
    "        if stdev_threshold is None:\n",
    "            print('Threshold for calculating standard deviation of absolute '\n",
    "                  'error is not defined. Input threshold value.')\n",
    "\n",
    "        metric = np.std(np.abs(pred_curr-pred_prev))\n",
    "\n",
    "        if scaled:\n",
    "            if scaling_method == 'max':\n",
    "                if rating_max is None:\n",
    "                    print('Scaled metric needs maximum possible value '\n",
    "                          'of rating.')\n",
    "                else:\n",
    "                    scaling_factor = rating_max\n",
    "            elif scaling_metho == 'minmax':\n",
    "                if (rating_max is None) or (rating_min is None):\n",
    "                    print(\n",
    "                        'Scaled metric needs maximum and minimum possible'\n",
    "                        ' values of rating.')\n",
    "                else:\n",
    "                    scaling_factor = (rating_max - rating_min)\n",
    "            metric /= scaling_factor\n",
    "\n",
    "        stop_train = (metric <= stdev_threshold)\n",
    "\n",
    "    else:\n",
    "        if mse_threshold is None:\n",
    "            print('Stopping criterion set to MSE. Input threshold value.')\n",
    "        metric = mean_squared_error(pred_curr, pred_prev)\n",
    "\n",
    "        stop_train = (metric <= mse_threshold)\n",
    "\n",
    "    return metric, stop_train\n",
    "\n",
    "\n",
    "def train_model_itemwise(\n",
    "        U_df, model_object, return_models=True, max_iter=100,\n",
    "        stopping_criterion='mse', mse_threshold=0.1, stdev_threshold=None,\n",
    "        scaled=False, scaling_method='max', rating_min=None, rating_max=None):\n",
    "    \"\"\"\n",
    "    Trains model iteratively for the item-wise recommender system: \n",
    "    (1) Estimates the missing entries of each column/item by setting it as \n",
    "    the target variable and the remaining columns as the feature variables. \n",
    "    (2) For the remaining columns, the current set of filled in values are \n",
    "    used to create a complete matrix of feature variables. \n",
    "    (3) The observed ratings in the target column are used for training. \n",
    "    (4) The missing entries are updated based on the prediction of the model \n",
    "    on each target column. \n",
    "\n",
    "    Parameters:\n",
    "        U_df (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        model_object : model object to use to fit the data\n",
    "        return_models (bool) : Indicates whether trained models are returned \n",
    "            as output, default True\n",
    "        max_iter (int) : maximum number of iterations for model training and \n",
    "            updatingof missing values, default 100\n",
    "        stopping_criterion (str) : metric for evaluating convergence, \n",
    "            {mse/'mean squared error', stdev_abs/'standard deviation of \n",
    "            absolute difference'}, default 'mse'\n",
    "        mse_threshold (float) : threshold for stopping criterion when \n",
    "            'mse'is selected, default 0.1            \n",
    "        stdev_threshold (float) : threshold for stopping criterion when \n",
    "            'stdev_abs'is selected, default None\n",
    "        scaled (bool) : Indicates whether metric for stopping criterion is \n",
    "            to be scaled/normalized\n",
    "        scaling_method (str) : indicates method for scaling when scaled==True, \n",
    "            {max/'maximum rating', minmax/'maximum rating - minimum rating'},\n",
    "            default 'max'\n",
    "        rating_min (numeric) : minimum value of rating, default None\n",
    "        rating_max (numeric) : maximum value of rating, default None\n",
    "\n",
    "    Returns:\n",
    "        U_update (DataFrame) : complete utility matrix\n",
    "        metric_iter (array-like) : value of convergence metric per iteration\n",
    "        models_item (dict) : dictionary of trained models, returned only if\n",
    "            return_models=True\n",
    "    \"\"\"\n",
    "    # VARS\n",
    "    U = U_df.copy()\n",
    "    U_update = U.copy()\n",
    "\n",
    "    models_item = initialize_models_itemwise(model = model_object, U = U, suffix='')\n",
    "\n",
    "    known_index, missing_index = known_missing_split_U(\n",
    "        U=U, split_axis=1, missing_val_filled=True)\n",
    "\n",
    "    len_missing_vals = len(sum([i.tolist()\n",
    "                                for i in missing_index.values()], []))\n",
    "\n",
    "    preds_per_iter = [np.zeros(len_missing_vals)]\n",
    "    metric_iter = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        preds = []\n",
    "        for item in U.columns:\n",
    "            models_item[str(item)].fit(\n",
    "                U_update.drop(item, axis=1).loc[known_index[item]],\n",
    "                U_update.loc[known_index[item], item])\n",
    "            if len(missing_index[item]) > 0:\n",
    "                pred = models_item[str(item)].predict(\n",
    "                    U_update.drop(item, axis=1).loc[missing_index[item]])\n",
    "            else:\n",
    "                pred = np.array([])\n",
    "            preds.append(pred)\n",
    "            U_update.loc[missing_index[item], item] = pred\n",
    "\n",
    "        metric, stopping_criterion = eval_convergence_criterion(\n",
    "            np.hstack(preds),\n",
    "            preds_per_iter[-1],\n",
    "            stopping_criterion=stopping_criterion,\n",
    "            mse_threshold=mse_threshold,\n",
    "            stdev_threshold=stdev_threshold,\n",
    "            scaled=scaled,\n",
    "            scaling_method=scaling_method,\n",
    "            rating_min=rating_min,\n",
    "            rating_max=rating_min)\n",
    "        metric_iter.append(metric)\n",
    "        if stopping_criterion:\n",
    "            break\n",
    "        preds_per_iter.append(np.hstack(preds))\n",
    "\n",
    "    if return_models:\n",
    "        return U_update, metric_iter, models_item\n",
    "    else:\n",
    "        return U_update, metric_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e178e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.classifier import Random\n",
    "mlp1 = MLPRegressor(hidden_layer_sizes=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e32012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'6': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '17': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '34': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '50': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '150': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '170': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '186': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '260': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '296': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '308': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '318': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '345': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '357': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '539': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '608': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '742': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '780': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '832': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '852': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '866': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1014': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1036': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1080': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1187': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1214': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1253': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1259': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1296': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1387': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1449': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1527': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1569': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1663': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1682': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1688': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1717': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1729': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1870': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1882': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2011': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2024': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2028': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2073': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2078': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2080': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2321': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2329': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2396': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2406': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2476': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2528': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2594': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2692': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2724': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2924': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2959': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3011': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3033': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3317': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3341': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3752': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3763': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3948': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4262': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4993': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5378': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5470': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5502': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5672': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5945': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '6787': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7153': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7154': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7380': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '8533': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '8784': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '35957': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '46970': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '50068': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '51174': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '53464': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '56339': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '61024': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '71264': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '80219': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '81845': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '84772': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '86882': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '91529': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '92259': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '102123': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '111362': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '111844': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '112556': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '134170': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '142488': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '152081': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '165551': MLPRegressor(hidden_layer_sizes=(100, 100))}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = U_df_mc.copy()\n",
    "model_object = mlp1\n",
    "\n",
    "models_item = initialize_models_itemwise(U, model_object, suffix='')\n",
    "models_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b6216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>6</th>\n",
       "      <th>17</th>\n",
       "      <th>34</th>\n",
       "      <th>50</th>\n",
       "      <th>150</th>\n",
       "      <th>170</th>\n",
       "      <th>186</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>308</th>\n",
       "      <th>...</th>\n",
       "      <th>91529</th>\n",
       "      <th>92259</th>\n",
       "      <th>102123</th>\n",
       "      <th>111362</th>\n",
       "      <th>111844</th>\n",
       "      <th>112556</th>\n",
       "      <th>134170</th>\n",
       "      <th>142488</th>\n",
       "      <th>152081</th>\n",
       "      <th>165551</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  6       17      34      50      150     170     186     260     \\\n",
       "user_id                                                                   \n",
       "11          0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "20          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "item_id  296     308     ...  91529   92259   102123  111362  111844  112556  \\\n",
       "user_id                  ...                                                   \n",
       "11          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "20          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "33          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "item_id  134170  142488  152081  165551  \n",
       "user_id                                  \n",
       "11          0.0     0.0     0.0     0.0  \n",
       "20          0.0     0.0     0.0     0.0  \n",
       "21          0.0     0.0     0.0     0.0  \n",
       "33          0.0     0.0     0.0     0.0  \n",
       "41          0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7481983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 97)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/9zlry5nx05n9mwvb98mlsysc0000gn/T/ipykernel_85518/3067279802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mU_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_itemwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5d/9zlry5nx05n9mwvb98mlsysc0000gn/T/ipykernel_85518/1513264876.py\u001b[0m in \u001b[0;36mtrain_model_itemwise\u001b[0;34m(U_df, model_object, return_models, max_iter, stopping_criterion, mse_threshold, stdev_threshold, scaled, scaling_method, rating_min, rating_max)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             models_item[str(item)].fit(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mU_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 U_update.loc[known_index[item], item])\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    362\u001b[0m                       (not self.warm_start and not incremental))\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[0m\u001b[1;32m   1415\u001b[0m                                    \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dq/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    727\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 97)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "U_imputed, metrics, models = train_model_itemwise(U, model_object, return_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb093caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_imputed.add(U_df.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_imputed.add(U_df.mean(axis=1), axis=0).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9739fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly get an item from the item clusters\n",
    "top_k # top items\n",
    "\n",
    "# randomly select items randomly from top cluster: number of items in the cluster\n",
    "# if there's any spillover, randomly get from the next top cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebfb46f",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445159b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_users(self, model):\n",
    "    \"\"\"\n",
    "    Perform user-wise clustering and assign each user to a cluster.\n",
    "    \n",
    "    Paramters\n",
    "    ---------                  \n",
    "    model        : an sklearn model object\n",
    "                   An object with a fit_predict method. Used to cluster the\n",
    "                   users into groups with similar ratings of items.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model         : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    clusters of users from fname\n",
    "    \n",
    "    result        : dict\n",
    "                    A mapping of each user's cluster with the keys being the\n",
    "                    user_id and the values their cluster membership\n",
    "    \n",
    "    df            : pandas DataFrame\n",
    "                    Utility matrix derived from fname with the final column\n",
    "                    corresponding to the cluster membership of that user\n",
    "    \"\"\"\n",
    "\n",
    "    # SOME VARIABLES\n",
    "    df = self.utility_matrix # utility matrix    \n",
    "    df = df.fillna(0) # fillna with 0\n",
    "    \n",
    "    # Aggregation through tables\n",
    "    u_clusterer = model\n",
    "    u_predict = u_clusterer.fit_predict(df)\n",
    "    df['u_cluster'] = u_predict\n",
    "\n",
    "    model = u_clusterer\n",
    "    result = dict(df['u_cluster'])\n",
    "    \n",
    "    # Output variables\n",
    "    self.user_cluster_model = model # attach the user_cluster_model to the class\n",
    "    self.utility_matrix_w_user_clusters = df # utility matrix with user clusters\n",
    "    self.user_cluster_mapping_dict = result # mapping of users and cluster labels\n",
    "    self.users_clustered = True # tag that we clustered the users\n",
    "    \n",
    "    return model, result, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_items(self, model):\n",
    "    \n",
    "    # WE MIGHT WANT TO FIX TO DROP COLS AS HARD CODED INSTEAD OF AN ARGUMENT\n",
    "    # SO LONG AS WE STANDARDIZE THE INPUT\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform item-wise clustering and assign each item to a cluster of similar\n",
    "    items based on the users that \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "                   \n",
    "    model        : an sklearn model object\n",
    "                   An object with a fit_predict method. Used to cluster the\n",
    "                   users into groups with similar ratings of items.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model         : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    clusters of items from fname\n",
    "    \n",
    "    result        : dict\n",
    "                    A mapping of each item's cluster with the keys being the\n",
    "                    item_id and the values their cluster membership\n",
    "    \n",
    "    df_items      : pandas DataFrame\n",
    "                    Utility matrix derived from fname with the final column\n",
    "                    corresponding to the cluster membership of that item\n",
    "    \"\"\"\n",
    "\n",
    "    # SOME VARIABLES\n",
    "    df = self.utility_matrix # utility matrix      \n",
    "    df = self.utility_matrix # utility matrix    \n",
    "    df = df.fillna(0) # fillna with 0\n",
    "\n",
    "    df_items = df.T\n",
    "    i_clusterer = model\n",
    "\n",
    "    i_predict = i_clusterer.fit_predict(df_items)\n",
    "    df_items['i_cluster'] = i_predict\n",
    "\n",
    "    model = i_clusterer\n",
    "    result = dict(df_items['i_cluster'])\n",
    "    \n",
    "    # Output variables\n",
    "    self.item_cluster_model = model # attach the item_cluster_model to the class\n",
    "    self.utility_matrix_w_item_clusters = df_items # utility matrix with item clusters\n",
    "    self.item_cluster_mapping_dict = result # mapping of users and cluster labels    \n",
    "    self.items_clustered = True # tag that we clustered the items\n",
    "    \n",
    "    return model, result, df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fffa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_users = KMeans(n_clusters=10)\n",
    "km_items = KMeans(n_clusters=10)\n",
    "\n",
    "user_model, user_cluster_map, util_matrix_w_users = re.cluster_users(km_users)\n",
    "item_model, item_cluster_map, util_matrix_w_items = re.cluster_items(km_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.item_cluster_model, re.user_cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_w_user_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_w_item_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4087e4",
   "metadata": {},
   "source": [
    "### Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_assignment(self):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts the dictionary containing user_id and user_cluster assignment  \n",
    "    to a pandas data frame \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result        : dataframe of cluster assignments\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if self.users_clustered: # if we ran the cluster_users method: \n",
    "        data_name='user_id'        \n",
    "        cluster_name='u_cluster'        \n",
    "        self.user_assignment = pd.DataFrame(list(self.user_cluster_mapping_dict.items()), columns=[data_name, cluster_name])\n",
    "        self.user_assignment.set_index(data_name, inplace=True)\n",
    "        \n",
    "    if self.items_clustered: # if we ran the cluster_users method: \n",
    "        data_name='user_id'        \n",
    "        cluster_name='i_cluster'        \n",
    "        self.item_assignment = pd.DataFrame(list(self.item_cluster_mapping_dict.items()), columns=[data_name, cluster_name])\n",
    "        self.item_assignment.set_index(data_name, inplace=True)        \n",
    "    \n",
    "    return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.cluster_assignment()\n",
    "re.user_assignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb786c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.item_assignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e374e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "\n",
    "def utility_matrix_agg(self, u_agg='mean', i_agg='mean'):\n",
    "    \"\"\"\n",
    "    Aggregates the results of the clustering with respect to item clusters and user clusters.\n",
    "    ------\n",
    "    Methods : two possible ways to aggregate the results of cluster assignments in df_u and df_i are 'sum' and 'mean'\n",
    "    u_agg   : aggregration method to be used for users\n",
    "    \n",
    "    i_agg   : aggregation method to be used for items\n",
    "    \n",
    "    -----\n",
    "    Returns : utility matrix consisting of the aggregrated user clusters as rows and aggregated item clusters as columns\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # GET utility matrices with cluster labels\n",
    "    df_u = self.utility_matrix_w_user_clusters\n",
    "    df_i = self.utility_matrix_w_item_clusters\n",
    "\n",
    "    u_series = df_u['u_cluster']\n",
    "    i_series = df_i['i_cluster']\n",
    "\n",
    "    u_ids = np.unique(u_series.values)\n",
    "    i_ids = np.unique(i_series.values) \n",
    "\n",
    "    u_feats = {}\n",
    "    for u_id in u_ids: #u_ids are clusters of u_id\n",
    "        sub_df = df_u.groupby('u_cluster').get_group(\n",
    "            u_id).drop(columns=['u_cluster']).T\n",
    "        sub_df = sub_df.merge(i_series.reset_index(drop=True), left_index=True, right_index=True)\n",
    "\n",
    "        if u_agg == 'sum':\n",
    "            df_grp = sub_df.groupby('i_cluster').sum()\n",
    "        if u_agg == 'mean':\n",
    "            df_grp = sub_df.groupby('i_cluster').mean()\n",
    "        if not isinstance(u_agg,str):\n",
    "            df_grp = sub_df.groupby('i_cluster').apply(u_agg)\n",
    "\n",
    "        if i_agg == 'sum':\n",
    "            df_grp = df_grp.sum(axis=1)\n",
    "        if i_agg == 'mean':\n",
    "            df_grp = df_grp.mean(axis=1)\n",
    "        if not isinstance(i_agg,str):\n",
    "            df_grp = df_grp.apply(i_agg, axis=1)\n",
    "\n",
    "        u_feats[u_id] = df_grp\n",
    "    \n",
    "\n",
    "    u_matrix = pd.DataFrame()\n",
    "    for k, v in u_feats.items():\n",
    "        u_matrix = u_matrix.merge(v.rename(k), how='outer',\n",
    "                                  left_index=True, right_index=True)\n",
    "\n",
    "    # UPDATE THE UTILITY MATRIX\n",
    "    self.utility_matrix = u_matrix.fillna(0).T \n",
    "    self.utility_matrix.index.rename('u_cluster', inplace=True)\n",
    "    return self.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_agg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bcd90c",
   "metadata": {},
   "source": [
    "#### Clustered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acd6a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:28.922441Z",
     "start_time": "2021-09-23T02:16:28.912421Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def train_model_itemwise_cluster(Uc_df, n_synth_data=100, p=0.3):\n",
    "    synth_data = gen_missing_ratings(Uc_df, p=p, n_masks=n_synth_data)\n",
    "    um_output = []\n",
    "    for n in range(n_synth_data):\n",
    "#         print(n)\n",
    "        U_df = synth_data[n]\n",
    "        U_df_mc = mean_center_utilmat(U_df, axis=1, fillna=True, fill_val=0)\n",
    "        U_imputed, metrics, models = train_model_itemwise(\n",
    "            U_df_mc, mlp1, return_models=True)\n",
    "        um_output.append(U_imputed)\n",
    "    um_output = pd.concat(um_output)\n",
    "    return um_output.groupby(um_output.index).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21b67f",
   "metadata": {},
   "source": [
    "### Get Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd36e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:32.043058Z",
     "start_time": "2021-09-23T02:16:32.030948Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def get_rec(utility_matrix, utility_matrix_o, user_list, top_n, uc_assignment=None):\n",
    "    \n",
    "    \"\"\"Returns the top N item cluster recommendations for each user in the user list\n",
    "    \n",
    "            Parameters:\n",
    "                    utility_matrix (numpy.ndarray): Matrix of utilities for each user-item pairing\n",
    "                    utility_matrix_o (numpy.ndarray): Original utility matrix, before imputation\n",
    "                    user_list (array-like): List of users\n",
    "                    uc_assignment (array-like): List containing the cluster assignment of each user\n",
    "                    top_n (int): Number of item clusters to recommend\n",
    "\n",
    "            Returns:\n",
    "                    df_rec (pandas.DataFrame): Table containing the top N item cluster recommendations for each user in the user list\n",
    "                    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Don't recommend items that are already rated\n",
    "    utility_matrix[np.where(utility_matrix_o != 0)] = -np.inf\n",
    "    \n",
    "    # Get top N per user cluster\n",
    "    cluster_rec = utility_matrix.argsort()[:, -top_n:]\n",
    "\n",
    "    # Create recommendation table\n",
    "    df_rec = pd.DataFrame()\n",
    "    df_rec['user_id'] = user_list\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        df_rec['rank_'+str(i+1)] = np.zeros(df_rec.shape[0])\n",
    "        for j in range(df_rec.shape[0]):\n",
    "            if uc_assignment is None:\n",
    "                df_rec.iloc[j, i+1] = cluster_rec[user_list[j], top_n-i-1]\n",
    "            else:\n",
    "                df_rec.iloc[j, i+1] = cluster_rec[uc_assignment[user_list[j]], top_n-i-1]\n",
    "                \n",
    "    return df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915693bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def get_rec_item(df_rec, top_k, ic_assignment):\n",
    "    \n",
    "    \"\"\"Returns the top K item recommendations for each user in the user list. \n",
    "    Items are selected randomly from the top recommended item cluster, exhaustively. Left overs are taken from the next highest ranked item clusters in a cascading fashion.\n",
    "    \n",
    "            Parameters:\n",
    "                    df_rec (pandas.DataFrame): Table containing the top N item cluster recommendations for each user in the user list\n",
    "                    ic_assignment (array-like): List containing the cluster assignment of each item\n",
    "                    top_n (int): Number of items to recommend\n",
    "\n",
    "            Returns:\n",
    "                    df_rec_item (pandas.DataFrame): Table containing the top K item recommendations for each user in the user list\n",
    "                    \n",
    "    \"\"\"\n",
    "\n",
    "    # Create recommendation table\n",
    "    df_rec_item = pd.DataFrame()\n",
    "    df_rec_item['user_id'] = df_rec['user_id']\n",
    "    \n",
    "    for i in range(top_k):\n",
    "        df_rec_item['rank_'+str(i+1)] = np.zeros(df_rec_item.shape[0])\n",
    "        \n",
    "    #for j in range(df_rec_item.shape[0]):\n",
    "    #    df_rec_item.iloc[j, i+1] = \n",
    "                \n",
    "    return df_rec_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840391a",
   "metadata": {},
   "source": [
    "## Trying the entire pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49e8db",
   "metadata": {},
   "source": [
    "### Non-Clustering Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85799d00",
   "metadata": {},
   "source": [
    "### Clustering Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature = joblib.load(\"tmp_files/user_feature\")\n",
    "item_feature_table = joblib.load(\"tmp_files/item_feature_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2fb58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:20:12.741547Z",
     "start_time": "2021-09-23T02:17:57.273618Z"
    }
   },
   "outputs": [],
   "source": [
    "x_u, y_u, df_u = u_cluster(user_feature,\"kmeans\", u_clusters=10)\n",
    "x_i, y_i, df_i = i_cluster(item_feature_table,'kmeans', i_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ff729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:20:12.759368Z",
     "start_time": "2021-09-23T02:20:12.747847Z"
    }
   },
   "outputs": [],
   "source": [
    "uc_assignment = cluster_assignment(y_u, data_name='user_id')\n",
    "ic_assignment = cluster_assignment(y_i, data_name='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ic_assignment.head(3))\n",
    "display(uc_assignment.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf603c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_u.head(3))\n",
    "display(df_i.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef673732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:52:24.073789Z",
     "start_time": "2021-09-23T02:52:23.591329Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Uc = utility_matrix_agg(df_u, df_i, u_agg='sum', i_agg='sum')\n",
    "Uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34acefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(Uc, \"tmp_files/Uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c806fb",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da108b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uc = joblib.load(\"tmp_files/Uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdd946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "mlp1 = MLPRegressor(hidden_layer_sizes=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d55a43",
   "metadata": {},
   "source": [
    "* we can prob make the model an argument of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Uc_df_output = train_model_itemwise_cluster(Uc, n_synth_data=20, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ead55",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce014d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install resype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72715e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "# Francis to change the values to be the ratings e.g. 1,2,3,4,5\n",
    "# Francis to remove scaling\n",
    "\n",
    "# RESYPE PIPE\n",
    "re = resype(transaction_list, user_features, item_features)\n",
    "km = Kmeans(**params)\n",
    "re.cluster_fit(user_model=km, item_model=None, user_n=20, item_n=None, agg_func='sum')\n",
    "# Gilbert will update the function so it looks like the thing above\n",
    "\n",
    "# internal logic na self.is_clustered = True / False\n",
    "# if self.is_clustered, run the model for clustered UM, else run the model for unclustered\n",
    "ml = GBM(**params)\n",
    "re.fit(model=ml, method=\"iterative or svd\") \n",
    "# Eloi will update the model for clustered version\n",
    "# Eloi and Vinni will add iterative or svd logic\n",
    "# Eloi to add logic if ratings are 0s and 1s and with NaN - autodetect if just 0 and 1\n",
    "\n",
    "df_rec = re.get_rec(top_k=10, user_list = [1, 2, 3]) # Basti will update the logic for unclustered version\n",
    "\n",
    "# get_rec should assign for users not yet in the training set\n",
    "# limitation of the collaborative filtering model\n",
    "\n",
    "# Basti to prepare the Getting started\n",
    "# Gilbert to help with documentation after fixing the function\n",
    "# Francis to help with the documentation - if we need to do anything else\n",
    "# Issa to help with documentation - if we need to do anything else\n",
    "# Prince to compile to classes and prepare the website doc\n",
    "# Separate the functions -> 1 function is to 1 notebook. Show input and show output per function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907ae1e",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179bef9",
   "metadata": {},
   "source": [
    "Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f58afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd782cbb",
   "metadata": {},
   "source": [
    "## API (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ed11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules, methods, arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "item=1\n",
    "fig, ax = plt.subplots(1)\n",
    "Uc[item].plot(label='original')\n",
    "Uc_df_output[item].plot(label='model_output')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
