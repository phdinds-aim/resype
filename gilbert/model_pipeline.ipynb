{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f04820",
   "metadata": {},
   "source": [
    "# Model Pipeline \n",
    "This notebook uses code from the cross_val, sample_train_test, and evaluate pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15fff1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T15:03:11.866882Z",
     "start_time": "2021-10-08T15:03:11.292478Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rs_model1 = RandomForestRegressor(random_state=202109, n_jobs=-1)\n",
    "\n",
    "# df = pd.read_parquet('augmented_transaction_table.parquet').dropna()\n",
    "\n",
    "# item_df = pd.read_parquet('item_feature.parquet')\n",
    "# item_ids = item_df['movieId'].unique()\n",
    "# item_df = item_df.drop(columns=['movieId'])\n",
    "# user_df = pd.read_parquet('user_feature.parquet').drop(columns=['userId'])\n",
    "# user_ids = df['userId'].unique()\n",
    "\n",
    "\n",
    "def load_data(aug_tt, item_tt,user_tt):\n",
    "    \"\"\"\n",
    "    Load the data from the transaction tables\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    aug_tt       : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features, an item's features, and the user's\n",
    "                   rating for that item\n",
    "\n",
    "    item_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to an item's features\n",
    "\n",
    "    user_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df            : pandas DataFrame\n",
    "                    The augmented transaction table\n",
    "                    \n",
    "    item_df       : pandas DataFrame\n",
    "                    The item features as a transaction table\n",
    "                    \n",
    "    user_df       : pandas DataFrame\n",
    "                    The userfeatures as a transaction table\n",
    "                    \n",
    "    item_ids      : list\n",
    "                    All unique item ids\n",
    "                    \n",
    "    user_ids      : list\n",
    "                    All unique user ids\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_parquet(aug_tt).dropna()\n",
    "    item_df = pd.read_parquet(item_tt)\n",
    "    item_ids = item_df['movieId'].unique()\n",
    "    item_df = item_df.drop(columns=['movieId'])\n",
    "    user_df = pd.read_parquet(user_tt).drop(columns=['userId'])\n",
    "    user_ids = df['userId'].unique()\n",
    "    return df, item_df, user_df, item_ids, user_ids\n",
    "\n",
    "df, item_df, user_df, item_ids, user_ids = load_data('augmented_transaction_table.parquet',\n",
    "                                                    'item_feature.parquet',\n",
    "                                                    'user_feature.parquet')\n",
    "\n",
    "\n",
    "def fit_ml_cb(train_df, model, target_col='rating', drop_cols=['userId', 'movieId','timestamp']):\n",
    "    \"\"\"\n",
    "    Perform item-wise clustering and assign each item to a cluster of similar\n",
    "    items based on the users that \n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "\n",
    "    drop_cols    : list\n",
    "                   Columns to be dropped in train_df.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rs_model      : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    rating of a user for an object given the user's features\n",
    "                    and the item's features.\n",
    "    \"\"\"\n",
    "    rs_model = clone(model)\n",
    "    target = train_df[target_col].dropna().values.ravel()\n",
    "    train_df = train_df.drop(columns=[target_col]+drop_cols)\n",
    "    rs_model = model.fit(train_df, target)\n",
    "    return rs_model\n",
    "\n",
    "\n",
    "def reco_ml_cb(user_df, item_df, model_fitted):\n",
    "    \"\"\"\n",
    "    Completes the entire utility matrix based on the model passed\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    full_matrix  : a pandas DataFrame\n",
    "                   The completed utility matrix.\n",
    "    \"\"\"\n",
    "    recos = {}\n",
    "    c = 1\n",
    "    for u, u_feats in user_df.iterrows():\n",
    "        print(c, 'out of', len(user_df), end='\\r')\n",
    "        u_feats = pd.concat([pd.DataFrame(u_feats).T] *\n",
    "                            len(item_ids)).reset_index(drop=True)\n",
    "        a_feats = u_feats.join(item_df)\n",
    "        reco = pd.Series(model_fitted.predict(a_feats), index=item_ids)\n",
    "        recos[u] = reco\n",
    "        c += 1\n",
    "    full_matrix = pd.DataFrame.from_dict(recos, orient='index')\n",
    "    return full_matrix\n",
    "\n",
    "\n",
    "\n",
    "# def fit_ml_cb_all(c_transactions, model, target_col='rating'):\n",
    "#     # Unused Function\n",
    "#     c_models = {}\n",
    "#     for cluster, table in c_transactions.items():\n",
    "#         c_models[cluster] = fit_ml_cb(table, model, target_col)\n",
    "#     return c_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c04cc9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.245407Z",
     "start_time": "2021-10-08T14:34:07.241920Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx = np.cumsum(np.in1d(np.arange(len(df.index)), user_ids))\n",
    "# u_i_history = {}\n",
    "# for i in user_ids:\n",
    "#     for x in df.groupby('userId')['movieId'].get_group(i).index:\n",
    "#         u_i_history[x] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a9bf8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.316697Z",
     "start_time": "2021-10-08T14:34:07.300424Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_train_test(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits the transaction data into train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data         : pandas DataFrame for transaction table containing user, item, and ratings\n",
    "    \n",
    "    train_ratio  : the desired ratio of training set, while 1-train ratio is automatically set for the test set \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    df_train_fin : dataframe for the training set\n",
    "    \n",
    "    df_test_fin  : dataframe for the test set\n",
    "    \n",
    "    df_test_fin* : possible option is a pivoted df ready as the util matrix input of the recsys. In our case, the\n",
    "                   index='userId', columns='movieId', values='rating'. To generalize a transaction table, \n",
    "                   index=column[0], columns=itemId, values=rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_df_train = []\n",
    "    list_df_test = []\n",
    "    \n",
    "    #group by user id\n",
    "    d = dict(tuple(data.groupby(data.columns[0]))) #assuming column[0] is the userId\n",
    "    \n",
    "    #splitting randomly per user\n",
    "    for i in (d):\n",
    "        if len(d[i])<2:\n",
    "            list_df_test.append(d[i])\n",
    "            \n",
    "        else:            \n",
    "            df_train = d[i].sample(frac=train_ratio)  \n",
    "            ind = df_train.index\n",
    "            df_test = d[i].drop(ind)\n",
    "            list_df_train.append(df_train) \n",
    "            list_df_test.append(df_test)\n",
    "\n",
    "    # 2. merge selected train set per user to a single dataframe\n",
    "    df_train_fin = pd.concat(list_df_train)\n",
    "    df_test_fin = pd.concat(list_df_test)\n",
    "    \n",
    "    # 3. Option to pivot it to create the utility matrix ready as input for recsys\n",
    "    df_test_um = df_test_fin.pivot(index=df_test_fin.columns[0], columns=df_test_fin.columns[1], values=df_test_fin.columns[2])\n",
    "\n",
    "    # 4. get indices of train and test sets\n",
    "    indx_train = df_train_fin.index\n",
    "    indx_test = df_test_fin.index\n",
    "\n",
    "    return df_train_fin, df_test_fin, df_test_um, indx_train, indx_test #return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d90794e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.577951Z",
     "start_time": "2021-10-08T14:34:07.557500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(df_test_result, df_test_data):\n",
    "    \"\"\"\n",
    "    Calculates the mse and mae per user of the results of the recommender system for a given test set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_test_result   : utility matrix containing the result of the recommender systems\n",
    "    \n",
    "    df_test_data     : pivoted test data generated from splitting the transaction table and tested on the recommender systems\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    mse_list         : list of mean squared error for each user\n",
    "    \n",
    "    mae_list         : list of mean absolute error for each user\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "#     test indices first, all user ids should be represented in the test matrix \n",
    "    idx_orig_data = df_test_data.index\n",
    "    idx_result = df_test_result.index + 1\n",
    "    a=idx_orig_data.difference(idx_result)\n",
    "    \n",
    "    if len(a)==0:\n",
    "        print('proceed')\n",
    "        \n",
    "        for i in (df_test_result.index):\n",
    "            y_pred = df_test_result[df_test_result.index==i].fillna(0)\n",
    "            y = df_test_data[df_test_data.index==i+1].fillna(0)\n",
    "            y_pred = y_pred[y.columns]\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            mae = mean_absolute_error(y, y_pred)\n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "    return mse_list, mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eb5dd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.832074Z",
     "start_time": "2021-10-08T14:34:07.813364Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val(df, k, model, split_method='random'):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for different train and test sets.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df                    : the data to be split in the form of vanilla/transaction++ table (uid, iid, rating, timestamp)\n",
    "\n",
    "    k                     : the number of times splitting and learning with the model is desired\n",
    "    \n",
    "    model                 : an unfitted sklearn model\n",
    "\n",
    "    split_method          : 'random' splitting or 'chronological' splitting of the data\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    mse and mae           : error metrics using sklearn\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    mse = []\n",
    "    mae = []\n",
    "\n",
    "    if split_method == 'random':\n",
    "\n",
    "        for i in range(k):\n",
    "            print(i)\n",
    "            # 1. split\n",
    "            print('Starting splitting')\n",
    "            df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(\n",
    "                df, 0.7)\n",
    "            print('Finished splitting')\n",
    "            # 2. train with model\n",
    "            model_clone = clone(model)\n",
    "            print('Starting training')\n",
    "            model_clone_fit = fit_ml_cb(df_train, model_clone)\n",
    "            print('Finished training')\n",
    "            print('Starting completing matrix')\n",
    "            result = reco_ml_cb(user_df, list(df_test.index), item_df, model_clone_fit)\n",
    "            print('Finished completing matrix')\n",
    "            print('Starting computing MAE and MSE')\n",
    "            # 3. evaluate results (result is in the form of utility matrix)\n",
    "            mse_i, mae_i = evaluate(result, df_test_um)\n",
    "            print('Finished computing MAE and MSE')\n",
    "\n",
    "            mse.append(mse_i)\n",
    "            mae.append(mae_i)\n",
    "\n",
    "    elif split_method == 'chronological':\n",
    "\n",
    "        # 1. split\n",
    "        df_train, df_test, df_test_um, indx_train, indx_test = split_train_test_chronological(\n",
    "            df, 0.7)\n",
    "\n",
    "        print('Starting splitting')\n",
    "        print('Finished splitting')\n",
    "        # 2. train with model\n",
    "        model_clone = clone(model)\n",
    "        print('Starting training')\n",
    "        model_clone_fit = fit_ml_cb(df_train, model_clone)\n",
    "        print('Finished training')\n",
    "        print('Starting completing matrix')\n",
    "        result = reco_ml_cb(user_df, list(df_test.index), item_df, model_clone_fit)\n",
    "        print('Finished completing matrix')\n",
    "        print('Starting computing MAE and MSE')\n",
    "        # 3. evaluate results (result is in the form of utility matrix)\n",
    "        mse_i, mae_i = evaluate(result, df_test_um)\n",
    "        print('Finished computing MAE and MSE')\n",
    "\n",
    "        mse.append(mse_i)\n",
    "        mae.append(mae_i)\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734a6a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T15:11:28.310762Z",
     "start_time": "2021-10-08T15:11:28.305666Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mse, mae = cross_val(df,5,rs_model1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
