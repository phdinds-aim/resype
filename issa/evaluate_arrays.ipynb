{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929447e0",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "This notebook contains 2nd and 3rd of three functions:\n",
    "1. split_train_test: creates train and test sets by splitting the raw data 'user_feature.csv'.\n",
    "2. evaluate: calculates the mse and mae of the final recommendations to the actual recommendations based on the test set.\n",
    "3. append_error_to_df: for visualization purposes and for further exploration of the errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e325ef0",
   "metadata": {},
   "source": [
    "## Generating input data for unittesting purposes. \n",
    "The commented cells are for the purpose of testing the function and unittest only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88806b9f-9bb1-4435-8884-2ec80b34d0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:43:05.630477Z",
     "start_time": "2021-10-09T06:43:05.625040Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68969d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:18:08.379515Z",
     "start_time": "2021-10-09T06:18:08.214106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1        1     4.0\n",
       "1            1        3     4.0\n",
       "2            1        6     4.0\n",
       "3            1       47     5.0\n",
       "4            1       50     5.0\n",
       "...        ...      ...     ...\n",
       "100831     610   166534     4.0\n",
       "100832     610   168248     5.0\n",
       "100833     610   168250     5.0\n",
       "100834     610   168252     5.0\n",
       "100835     610   170875     3.0\n",
       "\n",
       "[100836 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv('user_feature.csv')\n",
    "# features = ['userId', 'movieId', 'rating']\n",
    "# # data\n",
    "# new_data=data[features]\n",
    "# new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d4b7a",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9aefc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:18:12.026766Z",
     "start_time": "2021-10-09T06:18:12.011519Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def split_train_test(data, train_ratio=0.7):\n",
    "#     \"\"\"\n",
    "#     Splits the transaction data into train and test sets.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data         : pandas DataFrame for transaction table containing user, item, and ratings\n",
    "    \n",
    "#     train_ratio  : the desired ratio of training set, while 1-train ratio is automatically set for the test set \n",
    "    \n",
    "    \n",
    "#     Returns\n",
    "#     ---------\n",
    "#     df_train_fin : dataframe for the training set\n",
    "    \n",
    "#     df_test_fin  : dataframe for the test set\n",
    "    \n",
    "#     df_test_fin* : possible option is a pivoted df ready as the util matrix input of the recsys. In our case, the\n",
    "#                    index='userId', columns='movieId', values='rating'. To generalize a transaction table, \n",
    "#                    index=column[0], columns=itemId, values=rating.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     list_df_train = []\n",
    "#     list_df_test = []\n",
    "    \n",
    "#     #group by user id\n",
    "#     d = dict(tuple(data.groupby(data.columns[0]))) #assuming column[0] is the userId\n",
    "    \n",
    "#     #splitting randomly per user\n",
    "#     for i in (d):\n",
    "#         if len(d[i])<2:\n",
    "#             print(len(d[i]))\n",
    "#             list_df_test.append(d[i])\n",
    "            \n",
    "#         else:            \n",
    "#             df_train = d[i].sample(frac=train_ratio)  \n",
    "#             ind = df_train.index\n",
    "#             df_test = d[i].drop(ind)\n",
    "#             list_df_train.append(df_train) \n",
    "#             list_df_test.append(df_test)\n",
    "\n",
    "#     # 2. merge selected train set per user to a single dataframe\n",
    "#     df_train_fin = pd.concat(list_df_train)\n",
    "#     df_test_fin = pd.concat(list_df_test)\n",
    "    \n",
    "#     # 3. Option to pivot it to create the utility matrix ready as input for recsys\n",
    "#     df_test_um = df_test_fin.pivot(index=df_test_fin.columns[0], columns=df_test_fin.columns[1], values=df_test_fin.columns[2])\n",
    "    \n",
    "#     # 4. get indices of train and test sets\n",
    "#     indx_train = df_train_fin.index\n",
    "#     indx_test = df_test_fin.index\n",
    "\n",
    "#     return df_train_fin, df_test_fin, df_test_um, indx_train, indx_test #return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6efd89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:18:52.990017Z",
     "start_time": "2021-10-09T06:18:52.628441Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(new_data, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ca7462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:28:45.473472Z",
     "start_time": "2021-10-09T06:28:45.464312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     1,      4,      9,     11,     14,     16,     20,     21,\n",
       "                22,     23,\n",
       "            ...\n",
       "            100782, 100785, 100787, 100796, 100799, 100803, 100811, 100812,\n",
       "            100815, 100834],\n",
       "           dtype='int64', length=30256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb4cf8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:43:11.013830Z",
     "start_time": "2021-10-09T06:43:11.000231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 5. , 5. , ..., 4.5, 3.5, 5. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test_truth = new_data.loc[pd.Index(indx_test), 'rating']\n",
    "# df_test_truth.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca8fe8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T07:19:01.411286Z",
     "start_time": "2021-10-09T07:19:01.402465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  9,  1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synthetic_result = np.random.randint(1,11,len(df_test_truth))\n",
    "# synthetic_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654061cd",
   "metadata": {},
   "source": [
    "## Metrics for the output of recommerder system\n",
    "Sample test is created using a subset of the test set, while synthetic result is created by inducing few modifications in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f149e921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T07:17:01.109716Z",
     "start_time": "2021-10-09T07:17:01.096531Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_arrays(model_result_arr, df_data, indx_test):\n",
    "    \"\"\"\n",
    "    Calculates the mse and mae of the recommender system for a given result and test set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model_result_arr   : ratings from the results of the recommender sys using test set\n",
    "    \n",
    "    df_test_truth      : the original dataframe for before splitting.\n",
    "                         the original ratings or ground truth from the test set will be extracted from here using indices\n",
    "                         \n",
    "    indx_test          : result indices of test set from splitting\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    mse                : mse value using sklearn \n",
    "    \n",
    "    mae                : mse value using sklearn \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_test_truth = df_data.loc[pd.Index(indx_test), df_data.columns[2]]\n",
    "    test_arr = df_test_truth.values\n",
    "         \n",
    "#     test indices first, all user ids should be represented in the test matrix \n",
    "\n",
    "    result_len = len(model_result_arr) \n",
    "    test_len = len(test_arr)\n",
    "      \n",
    "    if result_len!=test_len:\n",
    "        raise ValueError('the arrays are of different lengths %s in %s' % (result_len,test_len))\n",
    "        \n",
    "    else:\n",
    "        print('proceed')\n",
    "            \n",
    "        mse = mean_squared_error(test_arr, model_result_arr)\n",
    "        mae = mean_absolute_error(test_arr, model_result_arr)\n",
    "\n",
    "            \n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52704a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T07:17:02.950031Z",
     "start_time": "2021-10-09T07:17:02.935558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed\n",
      "13.235316961924907\n",
      "2.9707330777366474\n"
     ]
    }
   ],
   "source": [
    "mse, mae = evaluate_arrays(synthetic_result, new_data, indx_test)\n",
    "print(mse)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceaf017",
   "metadata": {},
   "source": [
    "## Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c11d634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T07:18:40.556339Z",
     "start_time": "2021-10-09T07:18:40.516956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_length (__main__.Test_evaluate_arrays) ... ok\n",
      "test_type_error (__main__.Test_evaluate_arrays) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.008s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fb1defaf7c0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas._testing import assert_index_equal\n",
    "# from pandas._testing import assert_frame_equal\n",
    "\n",
    "class Test_evaluate_arrays(unittest.TestCase):\n",
    "    \n",
    "    \n",
    "    def test_length(self): \n",
    "        df1 = pd.DataFrame({'u': [1,1,2,2,3,3,3,5,5,6], 'i': [3,4,5,6,7,1,2,3,1,0], 'r':[5,6,7,8,9,3,2,1,0,9]})\n",
    "        indx1= [2,3,4,5]\n",
    "        df_test_truth = df.loc[pd.Index(indx1), df.columns=='r']\n",
    "        arr_test = df_test_truth.values\n",
    "        arr_result = np.random.randint(1,11,len(df_test_truth))\n",
    "        self.assertEqual(len(arr_test), len(arr_result))\n",
    "        \n",
    "        \n",
    "    def test_type_error(self):\n",
    "        df2 = pd.DataFrame([[1,1,2], [2,3,3], [3,5,5], [3,4,5], [6,7,1], [2,3,1], [5,6,7], [8,9,3], [2,1,1]], index=[0,1,2,3,4,5,6,7,8], columns=['u', 'i', 'r'])\n",
    "        indx2=[2,3,4,5]\n",
    "        df_test_truth2 = df2.loc[pd.Index(indx2), df2.columns[2]]\n",
    "        test_arr = df_test_truth2.values\n",
    "        arr_result = np.random.randint(1,11,len(df_test_truth2))\n",
    "        mse, mae = evaluate_arrays(arr_result, df2, indx2)\n",
    "        self.assertIsNotNone(mae)\n",
    "        self.assertIsNotNone(mse)\n",
    "        \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e619995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
