{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f04820",
   "metadata": {},
   "source": [
    "# Model Pipeline \n",
    "This notebook uses code from the cross_val, sample_train_test, and evaluate pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15fff1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T15:03:11.866882Z",
     "start_time": "2021-10-08T15:03:11.292478Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rs_model1 = RandomForestRegressor(random_state=202109, n_jobs=-1)\n",
    "\n",
    "# df = pd.read_parquet('augmented_transaction_table.parquet').dropna()\n",
    "\n",
    "# item_df = pd.read_parquet('item_feature.parquet')\n",
    "# item_ids = item_df['movieId'].unique()\n",
    "# item_df = item_df.drop(columns=['movieId'])\n",
    "# user_df = pd.read_parquet('user_feature.parquet').drop(columns=['userId'])\n",
    "# user_ids = df['userId'].unique()\n",
    "\n",
    "\n",
    "def load_data(aug_tt, item_tt,user_tt):\n",
    "    \"\"\"\n",
    "    Load the data from the transaction tables\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    aug_tt       : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features, an item's features, and the user's\n",
    "                   rating for that item\n",
    "\n",
    "    item_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to an item's features\n",
    "\n",
    "    user_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df            : pandas DataFrame\n",
    "                    The augmented transaction table\n",
    "                    \n",
    "    item_df       : pandas DataFrame\n",
    "                    The item features as a transaction table\n",
    "                    \n",
    "    user_df       : pandas DataFrame\n",
    "                    The userfeatures as a transaction table\n",
    "                    \n",
    "    item_ids      : list\n",
    "                    All unique item ids\n",
    "                    \n",
    "    user_ids      : list\n",
    "                    All unique user ids\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_parquet(aug_tt).dropna()\n",
    "    item_df = pd.read_parquet(item_tt)\n",
    "    item_ids = item_df['movieId'].unique()\n",
    "    item_df = item_df.drop(columns=['movieId'])\n",
    "    user_df = pd.read_parquet(user_tt).drop(columns=['userId'])\n",
    "    user_ids = df['userId'].unique()\n",
    "    return df, item_df, user_df, item_ids, user_ids\n",
    "\n",
    "df, item_df, user_df, item_ids, user_ids = load_data('augmented_transaction_table.parquet',\n",
    "                                                    'item_feature.parquet',\n",
    "                                                    'user_feature.parquet')\n",
    "\n",
    "\n",
    "def fit_ml_cb(train_df, model, target_col='rating', drop_cols=['userId', 'movieId','timestamp']):\n",
    "    \"\"\"\n",
    "    Perform item-wise clustering and assign each item to a cluster of similar\n",
    "    items based on the users that \n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "\n",
    "    drop_cols    : list\n",
    "                   Columns to be dropped in train_df.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rs_model      : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    rating of a user for an object given the user's features\n",
    "                    and the item's features.\n",
    "    \"\"\"\n",
    "    rs_model = clone(model)\n",
    "    target = train_df[target_col].dropna().values.ravel()\n",
    "    train_df = train_df.drop(columns=[target_col]+drop_cols)\n",
    "    rs_model = model.fit(train_df, target)\n",
    "    return rs_model\n",
    "\n",
    "\n",
    "def reco_ml_cb(user_df, item_df, model_fitted):\n",
    "    \"\"\"\n",
    "    Completes the entire utility matrix based on the model passed\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    full_matrix  : a pandas DataFrame\n",
    "                   The completed utility matrix.\n",
    "    \"\"\"\n",
    "    recos = {}\n",
    "    c = 1\n",
    "    for u, u_feats in user_df.iterrows():\n",
    "        print(c, 'out of', len(user_df), end='\\r')\n",
    "        u_feats = pd.concat([pd.DataFrame(u_feats).T] *\n",
    "                            len(item_ids)).reset_index(drop=True)\n",
    "        a_feats = u_feats.join(item_df)\n",
    "        reco = pd.Series(model_fitted.predict(a_feats), index=item_ids)\n",
    "        recos[u] = reco\n",
    "        c += 1\n",
    "    full_matrix = pd.DataFrame.from_dict(recos, orient='index')\n",
    "    return full_matrix\n",
    "\n",
    "\n",
    "\n",
    "# def fit_ml_cb_all(c_transactions, model, target_col='rating'):\n",
    "#     # Unused Function\n",
    "#     c_models = {}\n",
    "#     for cluster, table in c_transactions.items():\n",
    "#         c_models[cluster] = fit_ml_cb(table, model, target_col)\n",
    "#     return c_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c04cc9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.245407Z",
     "start_time": "2021-10-08T14:34:07.241920Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx = np.cumsum(np.in1d(np.arange(len(df.index)), user_ids))\n",
    "# u_i_history = {}\n",
    "# for i in user_ids:\n",
    "#     for x in df.groupby('userId')['movieId'].get_group(i).index:\n",
    "#         u_i_history[x] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a9bf8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.316697Z",
     "start_time": "2021-10-08T14:34:07.300424Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_train_test(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits the transaction data into train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data         : pandas DataFrame for transaction table containing user, item, and ratings\n",
    "    \n",
    "    train_ratio  : the desired ratio of training set, while 1-train ratio is automatically set for the test set \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    df_train_fin : dataframe for the training set\n",
    "    \n",
    "    df_test_fin  : dataframe for the test set\n",
    "    \n",
    "    df_test_fin* : possible option is a pivoted df ready as the util matrix input of the recsys. In our case, the\n",
    "                   index='userId', columns='movieId', values='rating'. To generalize a transaction table, \n",
    "                   index=column[0], columns=itemId, values=rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_df_train = []\n",
    "    list_df_test = []\n",
    "    \n",
    "    #group by user id\n",
    "    d = dict(tuple(data.groupby(data.columns[0]))) #assuming column[0] is the userId\n",
    "    \n",
    "    #splitting randomly per user\n",
    "    for i in (d):\n",
    "        if len(d[i])<2:\n",
    "            list_df_test.append(d[i])\n",
    "            \n",
    "        else:            \n",
    "            df_train = d[i].sample(frac=train_ratio)  \n",
    "            ind = df_train.index\n",
    "            df_test = d[i].drop(ind)\n",
    "            list_df_train.append(df_train) \n",
    "            list_df_test.append(df_test)\n",
    "\n",
    "    # 2. merge selected train set per user to a single dataframe\n",
    "    df_train_fin = pd.concat(list_df_train)\n",
    "    df_test_fin = pd.concat(list_df_test)\n",
    "    \n",
    "    # 3. Option to pivot it to create the utility matrix ready as input for recsys\n",
    "    df_test_um = df_test_fin.pivot(index=df_test_fin.columns[0], columns=df_test_fin.columns[1], values=df_test_fin.columns[2])\n",
    "\n",
    "    # 4. get indices of train and test sets\n",
    "    indx_train = df_train_fin.index\n",
    "    indx_test = df_test_fin.index\n",
    "\n",
    "    return df_train_fin, df_test_fin, df_test_um, indx_train, indx_test #return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d90794e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.577951Z",
     "start_time": "2021-10-08T14:34:07.557500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(df_test_result, df_test_data):\n",
    "    \"\"\"\n",
    "    Calculates the mse and mae per user of the results of the recommender system for a given test set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_test_result   : utility matrix containing the result of the recommender systems\n",
    "    \n",
    "    df_test_data     : pivoted test data generated from splitting the transaction table and tested on the recommender systems\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    mse_list         : list of mean squared error for each user\n",
    "    \n",
    "    mae_list         : list of mean absolute error for each user\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "#     test indices first, all user ids should be represented in the test matrix \n",
    "    idx_orig_data = df_test_data.index\n",
    "    idx_result = df_test_result.index + 1\n",
    "    a=idx_orig_data.difference(idx_result)\n",
    "    \n",
    "    if len(a)==0:\n",
    "        print('proceed')\n",
    "        \n",
    "        for i in (df_test_result.index):\n",
    "            y_pred = df_test_result[df_test_result.index==i].fillna(0)\n",
    "            y = df_test_data[df_test_data.index==i+1].fillna(0)\n",
    "            y_pred = y_pred[y.columns]\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            mae = mean_absolute_error(y, y_pred)\n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "    return mse_list, mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eb5dd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:34:07.832074Z",
     "start_time": "2021-10-08T14:34:07.813364Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val(df, k, model, split_method='random'):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for different train and test sets.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df                    : the data to be split in the form of vanilla/transaction++ table (uid, iid, rating, timestamp)\n",
    "\n",
    "    k                     : the number of times splitting and learning with the model is desired\n",
    "    \n",
    "    model                 : an unfitted sklearn model\n",
    "\n",
    "    split_method          : 'random' splitting or 'chronological' splitting of the data\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    mse and mae           : error metrics using sklearn\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    mse = []\n",
    "    mae = []\n",
    "\n",
    "    if split_method == 'random':\n",
    "\n",
    "        for i in range(k):\n",
    "            print(i)\n",
    "            # 1. split\n",
    "            print('Starting splitting')\n",
    "            df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(\n",
    "                df, 0.7)\n",
    "            print('Finished splitting')\n",
    "            # 2. train with model\n",
    "            model_clone = clone(model)\n",
    "            print('Starting training')\n",
    "            model_clone_fit = fit_ml_cb(df_train, model_clone)\n",
    "            print('Finished training')\n",
    "            print('Starting completing matrix')\n",
    "            result = reco_ml_cb(user_df, list(df_test.index), item_df, model_clone_fit)\n",
    "            print('Finished completing matrix')\n",
    "            print('Starting computing MAE and MSE')\n",
    "            # 3. evaluate results (result is in the form of utility matrix)\n",
    "            mse_i, mae_i = evaluate(result, df_test_um)\n",
    "            print('Finished computing MAE and MSE')\n",
    "\n",
    "            mse.append(mse_i)\n",
    "            mae.append(mae_i)\n",
    "\n",
    "    elif split_method == 'chronological':\n",
    "\n",
    "        # 1. split\n",
    "        df_train, df_test, df_test_um, indx_train, indx_test = split_train_test_chronological(\n",
    "            df, 0.7)\n",
    "\n",
    "        print('Starting splitting')\n",
    "        print('Finished splitting')\n",
    "        # 2. train with model\n",
    "        model_clone = clone(model)\n",
    "        print('Starting training')\n",
    "        model_clone_fit = fit_ml_cb(df_train, model_clone)\n",
    "        print('Finished training')\n",
    "        print('Starting completing matrix')\n",
    "        result = reco_ml_cb(user_df, list(df_test.index), item_df, model_clone_fit)\n",
    "        print('Finished completing matrix')\n",
    "        print('Starting computing MAE and MSE')\n",
    "        # 3. evaluate results (result is in the form of utility matrix)\n",
    "        mse_i, mae_i = evaluate(result, df_test_um)\n",
    "        print('Finished computing MAE and MSE')\n",
    "\n",
    "        mse.append(mse_i)\n",
    "        mae.append(mae_i)\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "734a6a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:39:51.711390Z",
     "start_time": "2021-10-08T14:34:08.092963Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "ID: 0\n",
      "ID: 1\n",
      "ID: 2\n",
      "ID: 3\n",
      "ID: 4\n",
      "ID: 5\n",
      "ID: 6\n",
      "ID: 7\n",
      "ID: 8\n",
      "ID: 9\n",
      "ID: 10\n",
      "ID: 11\n",
      "ID: 12\n",
      "ID: 13\n",
      "ID: 14\n",
      "ID: 15\n",
      "ID: 16\n",
      "ID: 17\n",
      "ID: 18\n",
      "ID: 19\n",
      "ID: 20\n",
      "ID: 21\n",
      "ID: 22\n",
      "ID: 23\n",
      "ID: 24\n",
      "ID: 25\n",
      "ID: 26\n",
      "ID: 27\n",
      "ID: 28\n",
      "ID: 29\n",
      "ID: 30\n",
      "ID: 31\n",
      "ID: 32\n",
      "ID: 33\n",
      "ID: 34\n",
      "ID: 35\n",
      "ID: 36\n",
      "ID: 37\n",
      "ID: 38\n",
      "ID: 39\n",
      "ID: 40\n",
      "ID: 41\n",
      "ID: 42\n",
      "ID: 43\n",
      "ID: 44\n",
      "ID: 45\n",
      "ID: 46\n",
      "ID: 47\n",
      "ID: 48\n",
      "ID: 49\n",
      "ID: 50\n",
      "ID: 51\n",
      "ID: 52\n",
      "ID: 53\n",
      "ID: 54\n",
      "ID: 55\n",
      "ID: 56\n",
      "ID: 57\n",
      "ID: 58\n",
      "ID: 59\n",
      "ID: 60\n",
      "ID: 61\n",
      "ID: 62\n",
      "ID: 63\n",
      "ID: 64\n",
      "ID: 65\n",
      "ID: 66\n",
      "ID: 67\n",
      "ID: 68\n",
      "ID: 69\n",
      "ID: 70\n",
      "ID: 71\n",
      "ID: 72\n",
      "ID: 73\n",
      "ID: 74\n",
      "ID: 75\n",
      "ID: 76\n",
      "ID: 77\n",
      "ID: 78\n",
      "ID: 79\n",
      "ID: 80\n",
      "ID: 81\n",
      "ID: 82\n",
      "ID: 83\n",
      "ID: 84\n",
      "ID: 85\n",
      "ID: 86\n",
      "ID: 87\n",
      "ID: 88\n",
      "ID: 89\n",
      "ID: 90\n",
      "ID: 91\n",
      "ID: 92\n",
      "ID: 93\n",
      "ID: 94\n",
      "ID: 95\n",
      "ID: 96\n",
      "ID: 97\n",
      "ID: 98\n",
      "ID: 99\n",
      "ID: 100\n",
      "ID: 101\n",
      "ID: 102\n",
      "ID: 103\n",
      "ID: 104\n",
      "ID: 105\n",
      "ID: 106\n",
      "ID: 107\n",
      "ID: 108\n",
      "ID: 109\n",
      "ID: 110\n",
      "ID: 111\n",
      "ID: 112\n",
      "ID: 113\n",
      "ID: 114\n",
      "ID: 115\n",
      "ID: 116\n",
      "ID: 117\n",
      "ID: 118\n",
      "ID: 119\n",
      "ID: 120\n",
      "ID: 121\n",
      "ID: 122\n",
      "ID: 123\n",
      "ID: 124\n",
      "ID: 125\n",
      "ID: 126\n",
      "ID: 127\n",
      "ID: 128\n",
      "ID: 129\n",
      "ID: 130\n",
      "ID: 131\n",
      "ID: 132\n",
      "ID: 133\n",
      "ID: 134\n",
      "ID: 135\n",
      "ID: 136\n",
      "ID: 137\n",
      "ID: 138\n",
      "ID: 139\n",
      "ID: 140\n",
      "ID: 141\n",
      "ID: 142\n",
      "ID: 143\n",
      "ID: 144\n",
      "ID: 145\n",
      "ID: 146\n",
      "ID: 147\n",
      "ID: 148\n",
      "ID: 149\n",
      "ID: 150\n",
      "ID: 151\n",
      "ID: 152\n",
      "ID: 153\n",
      "ID: 154\n",
      "ID: 155\n",
      "ID: 156\n",
      "ID: 157\n",
      "ID: 158\n",
      "ID: 159\n",
      "ID: 160\n",
      "ID: 161\n",
      "ID: 162\n",
      "ID: 163\n",
      "ID: 164\n",
      "ID: 165\n",
      "ID: 166\n",
      "ID: 167\n",
      "ID: 168\n",
      "ID: 169\n",
      "ID: 170\n",
      "ID: 171\n",
      "ID: 172\n",
      "ID: 173\n",
      "ID: 174\n",
      "ID: 175\n",
      "ID: 176\n",
      "ID: 177\n",
      "ID: 178\n",
      "ID: 179\n",
      "ID: 180\n",
      "ID: 181\n",
      "ID: 182\n",
      "ID: 183\n",
      "ID: 184\n",
      "ID: 185\n",
      "ID: 186\n",
      "ID: 187\n",
      "ID: 188\n",
      "ID: 189\n",
      "ID: 190\n",
      "ID: 191\n",
      "ID: 192\n",
      "ID: 193\n",
      "ID: 194\n",
      "ID: 195\n",
      "ID: 196\n",
      "ID: 197\n",
      "ID: 198\n",
      "ID: 199\n",
      "ID: 200\n",
      "ID: 201\n",
      "ID: 202\n",
      "ID: 203\n",
      "ID: 204\n",
      "ID: 205\n",
      "ID: 206\n",
      "ID: 207\n",
      "ID: 208\n",
      "ID: 209\n",
      "ID: 210\n",
      "ID: 211\n",
      "ID: 212\n",
      "ID: 213\n",
      "ID: 214\n",
      "ID: 215\n",
      "ID: 216\n",
      "ID: 217\n",
      "ID: 218\n",
      "ID: 219\n",
      "ID: 220\n",
      "ID: 221\n",
      "ID: 222\n",
      "ID: 223\n",
      "ID: 224\n",
      "ID: 225\n",
      "ID: 226\n",
      "ID: 227\n",
      "ID: 228\n",
      "ID: 229\n",
      "ID: 230\n",
      "ID: 231\n",
      "ID: 232\n",
      "ID: 233\n",
      "ID: 234\n",
      "ID: 235\n",
      "ID: 236\n",
      "ID: 237\n",
      "ID: 238\n",
      "ID: 239\n",
      "ID: 240\n",
      "ID: 241\n",
      "ID: 242\n",
      "ID: 243\n",
      "ID: 244\n",
      "ID: 245\n",
      "ID: 246\n",
      "ID: 247\n",
      "ID: 248\n",
      "ID: 249\n",
      "ID: 250\n",
      "ID: 251\n",
      "ID: 252\n",
      "ID: 253\n",
      "ID: 254\n",
      "ID: 255\n",
      "ID: 256\n",
      "ID: 257\n",
      "ID: 258\n",
      "ID: 259\n",
      "ID: 260\n",
      "ID: 261\n",
      "ID: 262\n",
      "ID: 263\n",
      "ID: 264\n",
      "ID: 265\n",
      "ID: 266\n",
      "ID: 267\n",
      "ID: 268\n",
      "ID: 269\n",
      "ID: 270\n",
      "ID: 271\n",
      "ID: 272\n",
      "ID: 273\n",
      "ID: 274\n",
      "ID: 275\n",
      "ID: 276\n",
      "ID: 277\n",
      "ID: 278\n",
      "ID: 279\n",
      "ID: 280\n",
      "ID: 281\n",
      "ID: 282\n",
      "ID: 283\n",
      "ID: 284\n",
      "ID: 285\n",
      "ID: 286\n",
      "ID: 287\n",
      "ID: 288\n",
      "ID: 289\n",
      "ID: 290\n",
      "ID: 291\n",
      "ID: 292\n",
      "ID: 293\n",
      "ID: 294\n",
      "ID: 295\n",
      "ID: 296\n",
      "ID: 297\n",
      "ID: 298\n",
      "ID: 299\n",
      "ID: 300\n",
      "ID: 301\n",
      "ID: 302\n",
      "ID: 303\n",
      "ID: 304\n",
      "ID: 305\n",
      "ID: 306\n",
      "ID: 307\n",
      "ID: 308\n",
      "ID: 309\n",
      "ID: 310\n",
      "ID: 311\n",
      "ID: 312\n",
      "ID: 313\n",
      "ID: 314\n",
      "ID: 315\n",
      "ID: 316\n",
      "ID: 317\n",
      "ID: 318\n",
      "ID: 319\n",
      "ID: 320\n",
      "ID: 321\n",
      "ID: 322\n",
      "ID: 323\n",
      "ID: 324\n",
      "ID: 325\n",
      "ID: 326\n",
      "ID: 327\n",
      "ID: 328\n",
      "ID: 329\n",
      "ID: 330\n",
      "ID: 331\n",
      "ID: 332\n",
      "ID: 333\n",
      "ID: 334\n",
      "ID: 335\n",
      "ID: 336\n",
      "ID: 337\n",
      "ID: 338\n",
      "ID: 339\n",
      "ID: 340\n",
      "ID: 341\n",
      "ID: 342\n",
      "ID: 343\n",
      "ID: 344\n",
      "ID: 345\n",
      "ID: 346\n",
      "ID: 347\n",
      "ID: 348\n",
      "ID: 349\n",
      "ID: 350\n",
      "ID: 351\n",
      "ID: 352\n",
      "ID: 353\n",
      "ID: 354\n",
      "ID: 355\n",
      "ID: 356\n",
      "ID: 357\n",
      "ID: 358\n",
      "ID: 359\n",
      "ID: 360\n",
      "ID: 361\n",
      "ID: 362\n",
      "ID: 363\n",
      "ID: 364\n",
      "ID: 365\n",
      "ID: 366\n",
      "ID: 367\n",
      "ID: 368\n",
      "ID: 369\n",
      "ID: 370\n",
      "ID: 371\n",
      "ID: 372\n",
      "ID: 373\n",
      "ID: 374\n",
      "ID: 375\n",
      "ID: 376\n",
      "ID: 377\n",
      "ID: 378\n",
      "ID: 379\n",
      "ID: 380\n",
      "ID: 381\n",
      "ID: 382\n",
      "ID: 383\n",
      "ID: 384\n",
      "ID: 385\n",
      "ID: 386\n",
      "ID: 387\n",
      "ID: 388\n",
      "ID: 389\n",
      "ID: 390\n",
      "ID: 391\n",
      "ID: 392\n",
      "ID: 393\n",
      "ID: 394\n",
      "ID: 395\n",
      "ID: 396\n",
      "ID: 397\n",
      "ID: 398\n",
      "ID: 399\n",
      "ID: 400\n",
      "ID: 401\n",
      "ID: 402\n",
      "ID: 403\n",
      "ID: 404\n",
      "ID: 405\n",
      "ID: 406\n",
      "ID: 407\n",
      "ID: 408\n",
      "ID: 409\n",
      "ID: 410\n",
      "ID: 411\n",
      "ID: 412\n",
      "ID: 413\n",
      "ID: 414\n",
      "ID: 415\n",
      "ID: 416\n",
      "ID: 417\n",
      "ID: 418\n",
      "ID: 419\n",
      "ID: 420\n",
      "ID: 421\n",
      "ID: 422\n",
      "ID: 423\n",
      "ID: 424\n",
      "ID: 425\n",
      "ID: 426\n",
      "ID: 427\n",
      "ID: 428\n",
      "ID: 429\n",
      "ID: 430\n",
      "ID: 431\n",
      "ID: 432\n",
      "ID: 433\n",
      "ID: 434\n",
      "ID: 435\n",
      "ID: 436\n",
      "ID: 437\n",
      "ID: 438\n",
      "ID: 439\n",
      "ID: 440\n",
      "ID: 441\n",
      "ID: 442\n",
      "ID: 443\n",
      "ID: 444\n",
      "ID: 445\n",
      "ID: 446\n",
      "ID: 447\n",
      "ID: 448\n",
      "ID: 449\n",
      "ID: 450\n",
      "ID: 451\n",
      "ID: 452\n",
      "ID: 453\n",
      "ID: 454\n",
      "ID: 455\n",
      "ID: 456\n",
      "ID: 457\n",
      "ID: 458\n",
      "ID: 459\n",
      "ID: 460\n",
      "ID: 461\n",
      "ID: 462\n",
      "ID: 463\n",
      "ID: 464\n",
      "ID: 465\n",
      "ID: 466\n",
      "ID: 467\n",
      "ID: 468\n",
      "ID: 469\n",
      "ID: 470\n",
      "ID: 471\n",
      "ID: 472\n",
      "ID: 473\n",
      "ID: 474\n",
      "ID: 475\n",
      "ID: 476\n",
      "ID: 477\n",
      "ID: 478\n",
      "ID: 479\n",
      "ID: 480\n",
      "ID: 481\n",
      "ID: 482\n",
      "ID: 483\n",
      "ID: 484\n",
      "ID: 485\n",
      "ID: 486\n",
      "ID: 487\n",
      "ID: 488\n",
      "ID: 489\n",
      "ID: 490\n",
      "ID: 491\n",
      "ID: 492\n",
      "ID: 493\n",
      "ID: 494\n",
      "ID: 495\n",
      "ID: 496\n",
      "ID: 497\n",
      "ID: 498\n",
      "ID: 499\n",
      "ID: 500\n",
      "ID: 501\n",
      "ID: 502\n",
      "ID: 503\n",
      "ID: 504\n",
      "ID: 505\n",
      "ID: 506\n",
      "ID: 507\n",
      "ID: 508\n",
      "ID: 509\n",
      "ID: 510\n",
      "ID: 511\n",
      "ID: 512\n",
      "ID: 513\n",
      "ID: 514\n",
      "ID: 515\n",
      "ID: 516\n",
      "ID: 517\n",
      "ID: 518\n",
      "ID: 519\n",
      "ID: 520\n",
      "ID: 521\n",
      "ID: 522\n",
      "ID: 523\n",
      "ID: 524\n",
      "ID: 525\n",
      "ID: 526\n",
      "ID: 527\n",
      "ID: 528\n",
      "ID: 529\n",
      "ID: 530\n",
      "ID: 531\n",
      "ID: 532\n",
      "ID: 533\n",
      "ID: 534\n",
      "ID: 535\n",
      "ID: 536\n",
      "ID: 537\n",
      "ID: 538\n",
      "ID: 539\n",
      "ID: 540\n",
      "ID: 541\n",
      "ID: 542\n",
      "ID: 543\n",
      "ID: 544\n",
      "ID: 545\n",
      "ID: 546\n",
      "ID: 547\n",
      "ID: 548\n",
      "ID: 549\n",
      "ID: 550\n",
      "ID: 551\n",
      "ID: 552\n",
      "ID: 553\n",
      "ID: 554\n",
      "ID: 555\n",
      "ID: 556\n",
      "ID: 557\n",
      "ID: 558\n",
      "ID: 559\n",
      "ID: 560\n",
      "ID: 561\n",
      "ID: 562\n",
      "ID: 563\n",
      "ID: 564\n",
      "ID: 565\n",
      "ID: 566\n",
      "ID: 567\n",
      "ID: 568\n",
      "ID: 569\n",
      "ID: 570\n",
      "ID: 571\n",
      "ID: 572\n",
      "ID: 573\n",
      "ID: 574\n",
      "ID: 575\n",
      "ID: 576\n",
      "ID: 577\n",
      "ID: 578\n",
      "ID: 579\n",
      "ID: 580\n",
      "ID: 581\n",
      "ID: 582\n",
      "ID: 583\n",
      "ID: 584\n",
      "ID: 585\n",
      "ID: 586\n",
      "ID: 587\n",
      "ID: 588\n",
      "ID: 589\n",
      "ID: 590\n",
      "ID: 591\n",
      "ID: 592\n",
      "ID: 593\n",
      "ID: 594\n",
      "ID: 595\n",
      "ID: 596\n",
      "ID: 597\n",
      "ID: 598\n",
      "ID: 599\n",
      "ID: 600\n",
      "ID: 601\n",
      "ID: 602\n",
      "ID: 603\n",
      "ID: 604\n",
      "ID: 605\n",
      "ID: 606\n",
      "ID: 607\n",
      "ID: 608\n",
      "ID: 609\n",
      "Finished computing MAE and MSE\n",
      "1\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125622/3992313349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrs_model1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_125622/2697433660.py\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(df, k, model, split_method)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmodel_clone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mmodel_clone_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_ml_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting completing matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_125622/1715128947.py\u001b[0m in \u001b[0;36mfit_ml_cb\u001b[0;34m(train_df, model, target_col, drop_cols)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdrop_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mrs_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrs_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mse, mae = cross_val(df,5,rs_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1a160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T12:08:52.191609Z",
     "start_time": "2021-10-08T12:08:52.191595Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(df, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf1cf52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T12:08:52.192906Z",
     "start_time": "2021-10-08T12:08:52.192892Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cd76d2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T12:03:50.799411Z",
     "start_time": "2021-10-08T12:03:50.759950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>173619</th>\n",
       "      <th>173873</th>\n",
       "      <th>173941</th>\n",
       "      <th>174053</th>\n",
       "      <th>174055</th>\n",
       "      <th>174681</th>\n",
       "      <th>174727</th>\n",
       "      <th>175197</th>\n",
       "      <th>175569</th>\n",
       "      <th>175707</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows  6041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           NaN     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "606         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "607         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         2.5     2.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "609         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     5.0     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  173619  173873  173941  174053  174055  174681  \\\n",
       "userId                   ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "606         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "607         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "609         NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  174727  175197  175569  175707  \n",
       "userId                                   \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "606         NaN     NaN     NaN     NaN  \n",
       "607         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "609         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[610 rows x 6041 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_um"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
