{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f04820",
   "metadata": {},
   "source": [
    "# Model Pipeline \n",
    "This notebook uses code from the cross_val, sample_train_test, and evaluate pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15fff1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:12:36.221710Z",
     "start_time": "2021-10-09T11:12:35.532307Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def load_data(aug_tt, item_tt, user_tt):\n",
    "    \"\"\"\n",
    "    Load the data from the transaction tables\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    aug_tt       : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features, an item's features, and the user's\n",
    "                   rating for that item\n",
    "\n",
    "    item_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to an item's features\n",
    "\n",
    "    user_tt      : str\n",
    "                   File name of the parquet file with each row corresponding\n",
    "                   to a user's features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df            : pandas DataFrame\n",
    "                    The augmented transaction table\n",
    "\n",
    "    item_df       : pandas DataFrame\n",
    "                    The item features as a transaction table\n",
    "\n",
    "    user_df       : pandas DataFrame\n",
    "                    The userfeatures as a transaction table\n",
    "\n",
    "    item_ids      : list\n",
    "                    All unique item ids\n",
    "\n",
    "    user_ids      : list\n",
    "                    All unique user ids\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_parquet(aug_tt).dropna()\n",
    "    item_df = pd.read_parquet(item_tt)\n",
    "    item_ids = item_df['movieId'].unique()\n",
    "    item_df = item_df.drop(columns=['movieId'])\n",
    "    user_df = pd.read_parquet(user_tt).drop(columns=['userId'])\n",
    "    user_ids = df['userId'].unique()\n",
    "    return df, item_df, user_df, item_ids, user_ids\n",
    "\n",
    "\n",
    "def fit_ml_cb(train_df, model, target_col='rating', drop_cols=['userId', 'movieId', 'timestamp']):\n",
    "    \"\"\"\n",
    "    Perform item-wise clustering and assign each item to a cluster of similar\n",
    "    items based on the users that \n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "\n",
    "    drop_cols    : list\n",
    "                   Columns to be dropped in train_df.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rs_model      : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    rating of a user for an object given the user's features\n",
    "                    and the item's features.\n",
    "    \"\"\"\n",
    "    rs_model = clone(model)\n",
    "    target = train_df[target_col].dropna().values.ravel()\n",
    "    train_df = train_df.drop(columns=[target_col]+drop_cols)\n",
    "    rs_model = model.fit(train_df, target)\n",
    "    return rs_model\n",
    "\n",
    "\n",
    "def reco_ml_cb(user_df, item_df, item_ids, model_fitted):\n",
    "    \"\"\"\n",
    "    Completes the entire utility matrix based on the model passed\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    train_df     : pandas DataFrame\n",
    "                   The training set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model        : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float.\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    full_matrix  : a pandas DataFrame\n",
    "                   The completed utility matrix.\n",
    "    \"\"\"\n",
    "    recos = {}\n",
    "    c = 1\n",
    "    for u, u_feats in user_df.iterrows():\n",
    "        print(c, 'out of', len(user_df), end='\\r')\n",
    "        u_feats = pd.concat([pd.DataFrame(u_feats).T] *\n",
    "                            len(item_ids)).reset_index(drop=True)\n",
    "        a_feats = u_feats.join(item_df)\n",
    "        reco = pd.Series(model_fitted.predict(a_feats), index=item_ids)\n",
    "        recos[u] = reco\n",
    "        c += 1\n",
    "    full_matrix = pd.DataFrame.from_dict(recos, orient='index')\n",
    "    return full_matrix\n",
    "\n",
    "\n",
    "def reco_ml_cb_tt(df_test, model_fitted, target='rating', drop_cols=['userId', 'movieId', 'timestamp']):\n",
    "    \"\"\"\n",
    "    Make predictions on the test set and outputs an array of the predicted\n",
    "    values for them.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    df_test      : pandas DataFrame\n",
    "                   The test set as a transaction table. Each row\n",
    "                   corresponds to a user's features and that item's features\n",
    "                   along with the user's rating for that item.\n",
    "\n",
    "    model_fitted : an sklearn regressor object\n",
    "                   An object with a fit and predict method that outputs a\n",
    "                   float. Must be fitted already\n",
    "\n",
    "    target_col   : str\n",
    "                   The column corresponding to the rating.\n",
    "                   \n",
    "    drop_cols    : list\n",
    "                   Columns to be dropped in df_test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result        : numpy array\n",
    "                   The results of the model using df_test's features\n",
    "    \"\"\"\n",
    "    df_test = df_test.drop(columns=[target]+drop_cols)\n",
    "    result = model_fitted.predict(df_test)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9bf8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:12:36.231925Z",
     "start_time": "2021-10-09T11:12:36.224781Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, train_ratio=0.7,uid='userId', iid='movieId', rid='rating'):\n",
    "    \"\"\"\n",
    "    Splits the transaction data into train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data         : pandas DataFrame for transaction table containing user, item, and ratings\n",
    "    \n",
    "    train_ratio  : the desired ratio of training set, while 1-train ratio is automatically set for the test set \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    df_train_fin : dataframe for the training set\n",
    "    \n",
    "    df_test_fin  : dataframe for the test set\n",
    "    \n",
    "    df_test_fin* : possible option is a pivoted df ready as the util matrix input of the recsys. In our case, the\n",
    "                   index='userId', columns='movieId', values='rating'. To generalize a transaction table, \n",
    "                   index=column[0], columns=itemId, values=rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_df_train = []\n",
    "    list_df_test = []\n",
    "    \n",
    "    #group by user id\n",
    "    d = dict(tuple(data.groupby(data.columns[0]))) #assuming column[0] is the userId\n",
    "    \n",
    "    #splitting randomly per user\n",
    "    for i in (d):\n",
    "        if len(d[i])<2:\n",
    "            list_df_test.append(d[i])\n",
    "            \n",
    "        else:            \n",
    "            df_train = d[i].sample(frac=train_ratio)  \n",
    "            ind = df_train.index\n",
    "            df_test = d[i].drop(ind)\n",
    "            list_df_train.append(df_train) \n",
    "            list_df_test.append(df_test)\n",
    "\n",
    "    # 2. merge selected train set per user to a single dataframe\n",
    "    df_train_fin = pd.concat(list_df_train)\n",
    "    df_test_fin = pd.concat(list_df_test)\n",
    "    \n",
    "    # 3. Option to pivot it to create the utility matrix ready as input for recsys\n",
    "    df_test_um = df_test_fin.pivot(index=uid, columns=iid, values=rid)\n",
    "    \n",
    "    # 4. get indices of train and test sets\n",
    "    indx_train = df_train_fin.index\n",
    "    indx_test = df_test_fin.index\n",
    "\n",
    "    return df_train_fin, df_test_fin, df_test_um, indx_train, indx_test #return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d90794e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:12:36.242724Z",
     "start_time": "2021-10-09T11:12:36.233897Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate(df_test_result, df_test_data):\n",
    "    \"\"\"\n",
    "    Calculates the mse and mae per user of the results of the recommender system for a given test set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_test_result   : utility matrix containing the result of the recommender systems\n",
    "    \n",
    "    df_test_data     : pivoted test data generated from splitting the transaction table and tested on the recommender systems\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    mse_list         : list of mean squared error for each user\n",
    "    \n",
    "    mae_list         : list of mean absolute error for each user\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "#     test indices first, all user ids should be represented in the test matrix \n",
    "    idx_orig_data = df_test_data.index\n",
    "    idx_result = df_test_result.index\n",
    "    a=idx_orig_data.difference(idx_result)\n",
    "    \n",
    "    if len(a)==0:\n",
    "        print('proceed')\n",
    "        for i in (df_test_result.index):\n",
    "            y_pred = df_test_result[df_test_result.index==i].fillna(0)\n",
    "            y = df_test_data[df_test_data.index==i].fillna(0)\n",
    "            y_pred = y_pred[y.columns]\n",
    "\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "    return mse_list, mae_list\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_arrays(model_result_arr, df_data, indx_test):\n",
    "    \"\"\"\n",
    "    Calculates the mse and mae of the recommender system for a given result and test set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model_result_arr   : ratings from the results of the recommender sys using test set\n",
    "    \n",
    "    df_test_truth      : the original dataframe for before splitting.\n",
    "                         the original ratings or ground truth from the test set will be extracted from here using indices\n",
    "                         \n",
    "    indx_test          : result indices of test set from splitting\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    mse                : mse value using sklearn \n",
    "    \n",
    "    mae                : mse value using sklearn \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_test_truth = df_data.loc[pd.Index(indx_test), df_data.columns[2]]\n",
    "    test_arr = df_test_truth.values\n",
    "         \n",
    "#     test indices first, all user ids should be represented in the test matrix \n",
    "\n",
    "    result_len = len(model_result_arr) \n",
    "    test_len = len(test_arr)\n",
    "      \n",
    "    if result_len!=test_len:\n",
    "        raise ValueError('the arrays are of different lengths %s in %s' % (result_len,test_len))\n",
    "        \n",
    "    else:\n",
    "        print('proceed')\n",
    "            \n",
    "        mse = mean_squared_error(test_arr, model_result_arr)\n",
    "        mae = mean_absolute_error(test_arr, model_result_arr)\n",
    "\n",
    "            \n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb5dd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:14:29.524226Z",
     "start_time": "2021-10-09T11:14:29.503117Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val(df, k, model, split_method='random'):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for different train and test sets.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df                    : the data to be split in the form of vanilla/transaction++ table (uid, iid, rating, timestamp)\n",
    "\n",
    "    k                     : the number of times splitting and learning with the model is desired\n",
    "    \n",
    "    model                 : an unfitted sklearn model\n",
    "\n",
    "    split_method          : 'random' splitting or 'chronological' splitting of the data\n",
    "\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    mse and mae           : error metrics using sklearn\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    mse = []\n",
    "    mae = []\n",
    "\n",
    "    if split_method == 'random':\n",
    "\n",
    "        for i in range(k):\n",
    "            print(i)\n",
    "            # 1. split\n",
    "            print('Starting splitting')\n",
    "            df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(\n",
    "                df, 0.7)\n",
    "            print('Finished splitting')\n",
    "            # 2. train with model\n",
    "            model_clone = clone(model)\n",
    "            print('Starting training')\n",
    "            model_clone_fit = fit_ml_cb(df_train.sample(100), model_clone)\n",
    "            print('Finished training')\n",
    "            print('Starting completing matrix')\n",
    "            result = reco_ml_cb_tt(df_test, model_fit)\n",
    "            print('Finished completing matrix')\n",
    "            print('Starting computing MAE and MSE')\n",
    "            # 3. evaluate results (result is in the form of utility matrix)\n",
    "            mse_i, mae_i = evaluate_arrays(result, df, indx_test)\n",
    "            print('Finished computing MAE and MSE')\n",
    "\n",
    "            mse.append(mse_i)\n",
    "            mae.append(mae_i)\n",
    "\n",
    "    elif split_method == 'chronological':\n",
    "\n",
    "        # 1. split\n",
    "        df_train, df_test, df_test_um, indx_train, indx_test = split_train_test_chronological(\n",
    "            df, 0.7)\n",
    "\n",
    "        print('Starting splitting')\n",
    "        print('Finished splitting')\n",
    "        # 2. train with model\n",
    "        model_clone = clone(model)\n",
    "        print('Starting training')\n",
    "        model_clone_fit = fit_ml_cb(df_train.sample(100), model_clone)\n",
    "        print('Finished training')\n",
    "        print('Starting completing matrix')\n",
    "        result = reco_ml_cb_tt(df_test, model_fit)\n",
    "        print('Finished completing matrix')\n",
    "        print('Starting computing MAE and MSE')\n",
    "        # 3. evaluate results (result is in the form of utility matrix)\n",
    "        mse_i, mae_i = evaluate_arrays(result, df, indx_test)\n",
    "        print('Finished computing MAE and MSE')\n",
    "\n",
    "        mse.append(mse_i)\n",
    "        mae.append(mae_i)\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118be231",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a40e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:13:20.240895Z",
     "start_time": "2021-10-09T11:13:17.656665Z"
    }
   },
   "outputs": [],
   "source": [
    "#Declare your model\n",
    "rs_model1 = RandomForestRegressor(random_state=202109, n_jobs=-1)\n",
    "#Load the data\n",
    "df, item_df, user_df, item_ids, user_ids = load_data('augmented_transaction_table.parquet',\n",
    "                                                     'item_feature.parquet',\n",
    "                                                     'user_feature.parquet')\n",
    "#Do your train and test split\n",
    "df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(df, 0.7) #To split the data\n",
    "# #Fit your model to the train data\n",
    "model_fit = fit_ml_cb(df_train.sample(100), rs_model1) #To fit the model\n",
    "#Predict on the test data\n",
    "preds_array = reco_ml_cb_tt(df_test, model_fit) #To make predictions as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d1cb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:14:56.655129Z",
     "start_time": "2021-10-09T11:14:45.684633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "Finished computing MAE and MSE\n",
      "1\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "Finished computing MAE and MSE\n",
      "2\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "Finished computing MAE and MSE\n",
      "3\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "Finished computing MAE and MSE\n",
      "4\n",
      "Starting splitting\n",
      "Finished splitting\n",
      "Starting training\n",
      "Finished training\n",
      "Starting completing matrix\n",
      "Finished completing matrix\n",
      "Starting computing MAE and MSE\n",
      "proceed\n",
      "Finished computing MAE and MSE\n"
     ]
    }
   ],
   "source": [
    "mse, mae = cross_val(df, 5, model_fit, split_method='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83b5a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:13:09.393305Z",
     "start_time": "2021-10-09T11:13:09.370678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8669795716126364, 0.7143198938393699)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_arrays(preds_array, df, indx_test) #MSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7abfa8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:13:09.398031Z",
     "start_time": "2021-10-09T11:13:09.395105Z"
    }
   },
   "outputs": [],
   "source": [
    "# preds_matrix = reco_ml_cb(user_df, item_df, model_fit) #To complete the utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac7289",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-09T08:08:59.325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_array_pred (__main__.TestGetRec) ... "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>u_1</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>...</th>\n",
       "      <th>i_291</th>\n",
       "      <th>i_292</th>\n",
       "      <th>i_293</th>\n",
       "      <th>i_294</th>\n",
       "      <th>i_295</th>\n",
       "      <th>i_296</th>\n",
       "      <th>i_297</th>\n",
       "      <th>i_298</th>\n",
       "      <th>i_299</th>\n",
       "      <th>i_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981208</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981179</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>610</td>\n",
       "      <td>161582</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493847759</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100826</th>\n",
       "      <td>610</td>\n",
       "      <td>162350</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493849971</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100829</th>\n",
       "      <td>610</td>\n",
       "      <td>164179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493845631</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30101 rows × 324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp  u_1  u_2  u_3  u_4  u_5  u_6  \\\n",
       "1            1        3     4.0   964981247   85   29   42   83   47   26   \n",
       "2            1        6     4.0   964982224   85   29   42   83   47   26   \n",
       "5            1       70     3.0   964982400   85   29   42   83   47   26   \n",
       "11           1      216     5.0   964981208   85   29   42   83   47   26   \n",
       "18           1      333     5.0   964981179   85   29   42   83   47   26   \n",
       "...        ...      ...     ...         ...  ...  ...  ...  ...  ...  ...   \n",
       "100824     610   161582     4.0  1493847759  267   66   56  411  151  119   \n",
       "100826     610   162350     3.5  1493849971  267   66   56  411  151  119   \n",
       "100829     610   164179     5.0  1493845631  267   66   56  411  151  119   \n",
       "100834     610   168252     5.0  1493846352  267   66   56  411  151  119   \n",
       "100835     610   170875     3.0  1493846415  267   66   56  411  151  119   \n",
       "\n",
       "        ...  i_291  i_292     i_293  i_294  i_295     i_296  i_297     i_298  \\\n",
       "1       ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "2       ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "5       ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "11      ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.448884   \n",
       "18      ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "...     ...    ...    ...       ...    ...    ...       ...    ...       ...   \n",
       "100824  ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "100826  ...    0.0    0.0  0.000000    0.0    0.0  0.000000    0.0  0.000000   \n",
       "100829  ...    0.0    0.0  0.000000    0.0    0.0  0.296870    0.0  0.000000   \n",
       "100834  ...    0.0    0.0  0.000000    0.0    0.0  0.291784    0.0  0.000000   \n",
       "100835  ...    0.0    0.0  0.365896    0.0    0.0  0.313337    0.0  0.000000   \n",
       "\n",
       "        i_299     i_300  \n",
       "1         0.0  0.000000  \n",
       "2         0.0  0.000000  \n",
       "5         0.0  0.000000  \n",
       "11        0.0  0.000000  \n",
       "18        0.0  0.000000  \n",
       "...       ...       ...  \n",
       "100824    0.0  0.000000  \n",
       "100826    0.0  0.000000  \n",
       "100829    0.0  0.000000  \n",
       "100834    0.0  0.282198  \n",
       "100835    0.0  0.000000  \n",
       "\n",
       "[30101 rows x 324 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_matrix_shape (__main__.TestGetRec) ... "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>u_1</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>...</th>\n",
       "      <th>i_291</th>\n",
       "      <th>i_292</th>\n",
       "      <th>i_293</th>\n",
       "      <th>i_294</th>\n",
       "      <th>i_295</th>\n",
       "      <th>i_296</th>\n",
       "      <th>i_297</th>\n",
       "      <th>i_298</th>\n",
       "      <th>i_299</th>\n",
       "      <th>i_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>610</td>\n",
       "      <td>158956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848947</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100819</th>\n",
       "      <td>610</td>\n",
       "      <td>160080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848031</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100827</th>\n",
       "      <td>610</td>\n",
       "      <td>163937</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493848789</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100828</th>\n",
       "      <td>610</td>\n",
       "      <td>163981</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493850155</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "      <td>267</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>411</td>\n",
       "      <td>151</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30101 rows × 324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp  u_1  u_2  u_3  u_4  u_5  u_6  \\\n",
       "0            1        1     4.0   964982703   85   29   42   83   47   26   \n",
       "4            1       50     5.0   964982931   85   29   42   83   47   26   \n",
       "5            1       70     3.0   964982400   85   29   42   83   47   26   \n",
       "6            1      101     5.0   964980868   85   29   42   83   47   26   \n",
       "8            1      151     5.0   964984041   85   29   42   83   47   26   \n",
       "...        ...      ...     ...         ...  ...  ...  ...  ...  ...  ...   \n",
       "100817     610   158956     3.0  1493848947  267   66   56  411  151  119   \n",
       "100819     610   160080     3.0  1493848031  267   66   56  411  151  119   \n",
       "100827     610   163937     3.5  1493848789  267   66   56  411  151  119   \n",
       "100828     610   163981     3.5  1493850155  267   66   56  411  151  119   \n",
       "100832     610   168248     5.0  1493850091  267   66   56  411  151  119   \n",
       "\n",
       "        ...  i_291  i_292  i_293  i_294  i_295    i_296  i_297  i_298  i_299  \\\n",
       "0       ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "4       ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "5       ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "6       ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "8       ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...      ...    ...    ...    ...   \n",
       "100817  ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "100819  ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "100827  ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "100828  ...    0.0    0.0    0.0    0.0    0.0  0.00000    0.0    0.0    0.0   \n",
       "100832  ...    0.0    0.0    0.0    0.0    0.0  0.24502    0.0    0.0    0.0   \n",
       "\n",
       "        i_300  \n",
       "0         0.0  \n",
       "4         0.0  \n",
       "5         0.0  \n",
       "6         0.0  \n",
       "8         0.0  \n",
       "...       ...  \n",
       "100817    0.0  \n",
       "100819    0.0  \n",
       "100827    0.0  \n",
       "100828    0.0  \n",
       "100832    0.0  \n",
       "\n",
       "[30101 rows x 324 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 out of 610\r"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestGetRec(unittest.TestCase):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.base import clone\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    def test_matrix_shape(self):\n",
    "        df, item_df, user_df, item_ids, user_ids = load_data('augmented_transaction_table.parquet',\n",
    "                                                     'item_feature.parquet',\n",
    "                                                     'user_feature.parquet')\n",
    "        df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(df, 0.7) #To split the data\n",
    "        model_fit = fit_ml_cb(df_train.sample(100), rs_model1) \n",
    "        matrix_result = reco_ml_cb(user_df, item_df, item_ids, model_fit)\n",
    "        self.assertEqual(matrix_result.shape[0], len(user_ids))\n",
    "        self.assertEqual(matrix_result.shape[1], len(item_ids))\n",
    "\n",
    "    def test_array_pred(self):\n",
    "        df, item_df, user_df, item_ids, user_ids = load_data('augmented_transaction_table.parquet',\n",
    "                                                     'item_feature.parquet',\n",
    "                                                     'user_feature.parquet')\n",
    "        df_train, df_test, df_test_um, indx_train, indx_test = split_train_test(df, 0.7) #To split the data\n",
    "        model_fit = fit_ml_cb(df_train.sample(100), rs_model1) \n",
    "        array_result = reco_ml_cb_tt(df_test, model_fit)\n",
    "        self.assertEqual(len(array_result), len(df_test))        \n",
    "        \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
