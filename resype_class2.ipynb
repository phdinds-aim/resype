{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReSyPE Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:15:54.516615Z",
     "start_time": "2021-09-23T02:15:53.187035Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "import jdc\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReSyPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resype:\n",
    "    \"\"\"\n",
    "    Resype implements a machine learning framework for recommender systems.\n",
    "            Parameters:\n",
    "                    transaction_list (pandas.DataFrame): Dataframe with columns user_id, item_id, rating in the form\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 1     | 4    |\n",
    "                        \n",
    "            Final outputs:\n",
    "                    recommendations (pandas.DataFrame): Dataframe with columns user_id, item_id, score\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 3     | 2    |                    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_list):\n",
    "        \"\"\"\n",
    "            Parameters:\n",
    "                    transaction_list (pandas.DataFrame): Dataframe with columns user_id, item_id, rating in the form\n",
    "                        |user_id|item_id|rating|\n",
    "                        |=======|=======|======|\n",
    "                        | 1     | 1     | 4    |        \n",
    "        \"\"\"\n",
    "        self.transaction_list = transaction_list\n",
    "        self.users_clustered = False # whether the users were clustered\n",
    "        self.items_clustered = False # whether the items were clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def construct_utility_matrix(self):\n",
    "    self.utility_matrix = transaction_list.pivot(index='user_id', columns='item_id', values='rating') # utility matrix    \n",
    "    return self.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9266</th>\n",
       "      <td>63</td>\n",
       "      <td>3535</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19410</th>\n",
       "      <td>125</td>\n",
       "      <td>78349</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>160</td>\n",
       "      <td>2166</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53114</th>\n",
       "      <td>351</td>\n",
       "      <td>6539</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51425</th>\n",
       "      <td>332</td>\n",
       "      <td>1344</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "9266        63     3535     4.0\n",
       "19410      125    78349     3.5\n",
       "23476      160     2166     3.0\n",
       "53114      351     6539     4.0\n",
       "51425      332     1344     3.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_list = pd.read_csv(\"sample_data/ratings.csv\")[['userId', 'movieId', 'rating']]\n",
    "transaction_list = transaction_list.sample(100)\n",
    "transaction_list.columns = [\"user_id\", 'item_id', 'rating']\n",
    "\n",
    "re = Resype(transaction_list)\n",
    "re.transaction_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>97</th>\n",
       "      <th>141</th>\n",
       "      <th>227</th>\n",
       "      <th>260</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>344</th>\n",
       "      <th>370</th>\n",
       "      <th>...</th>\n",
       "      <th>89745</th>\n",
       "      <th>96448</th>\n",
       "      <th>98160</th>\n",
       "      <th>102125</th>\n",
       "      <th>106782</th>\n",
       "      <th>112552</th>\n",
       "      <th>122916</th>\n",
       "      <th>136834</th>\n",
       "      <th>142448</th>\n",
       "      <th>158238</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  22      25      97      141     227     260     281     282     \\\n",
       "user_id                                                                   \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  344     370     ...  89745   96448   98160   102125  106782  112552  \\\n",
       "user_id                  ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  122916  136834  142448  158238  \n",
       "user_id                                  \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "6           NaN     NaN     NaN     NaN  \n",
       "16          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "42          NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "597         NaN     NaN     NaN     NaN  \n",
       "600         NaN     NaN     NaN     NaN  \n",
       "603         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[81 rows x 98 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.construct_utility_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:18.560671Z",
     "start_time": "2021-09-23T02:16:18.525163Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def mean_center_utilmat(U_df, axis=1, fillna=True, fill_val=None):\n",
    "    \"\"\"Gets the mean-centered utility matrix\n",
    "\n",
    "        Parameters:\n",
    "                U_df (DataFrame): utility matrix (rows are users, columns are items) \n",
    "                axis (int): The axis along mean is evaluated, \n",
    "                    {0/'index', 1/'columns'}, default 1\n",
    "                fillna (bool): Indicates whether missing/null values are to \n",
    "                    be filled\n",
    "                fill_val (None/float) : Value to be used to fill null values \n",
    "                    when fillna==True, default None\n",
    "\n",
    "        Returns:\n",
    "            mean_centered (DataFrame): mean-centered utility matrix\n",
    "    \"\"\"\n",
    "    mean_centered = U_df.sub(U_df.mean(axis=axis), axis=1-axis)\n",
    "    if fillna:\n",
    "        if fill_val is not None:\n",
    "            return mean_centered.fillna(fill_val)\n",
    "        else:\n",
    "            return mean_centered.fillna(0)\n",
    "    else:\n",
    "        return mean_centered\n",
    "\n",
    "\n",
    "\n",
    "def split_utilmat_label_features(self, label_index, axis=1):\n",
    "    \"\"\"Splits utility matrix into label (column/row where ratings are predicted) \n",
    "    and features (columns/rows to be used as input in the model)\n",
    "\n",
    "        Parameters:\n",
    "                U_df (DataFrame): utility matrix (rows are users, columns are items) \n",
    "                label_index (int/str): column name or index corresponding to  item \n",
    "                    ratings (column) or user ratings (row) to be predicted\n",
    "                axis (int): The axis along the utility matrix is split, \n",
    "                    {0/'index', 1/'columns'}, default 1\n",
    "\n",
    "        Returns:\n",
    "                label_df (DataFrame): contains the column/row to be predicted\n",
    "                feature_df (DataFrame): contains the features   \n",
    "    \"\"\"\n",
    "    \n",
    "    # VARIABLES\n",
    "    U = self.utility_matrix\n",
    "    \n",
    "    if axis == 1:\n",
    "        label_col = U.columns[U.columns == label_index]\n",
    "        feature_col = U.columns[~(U.columns == label_index)]\n",
    "        label_df = U.loc[:, label_col]\n",
    "        feature_df = U.loc[:, feature_col]\n",
    "    elif axis == 0:\n",
    "        label_row = U.index[U.index == label_index]\n",
    "        feature_row = U.index[~(U.index == label_index)]\n",
    "        label_df = U.loc[label_row, :]\n",
    "        feature_df = U.loc[feature_row, :]\n",
    "\n",
    "    return label_df, feature_df\n",
    "\n",
    "\n",
    "def known_missing_split_1d(label_data, feature_data, split_axis=1,\n",
    "                           missing_val_filled=False, fill_val=None):\n",
    "    \"\"\"Returns index of the dataset corresponding to known and missing ratings\n",
    "    in the label data (row or column to be predicted)\n",
    "\n",
    "    Parameters:\n",
    "        label_df (DataFrame) : contains the column/row to be predicted\n",
    "        feature_df (DataFrame) : contains the features  \n",
    "        split_axis (int) : The axis along the utility matrix is split, \n",
    "            {0/'index', 1/'columns'}, default 1\n",
    "        missing_val_filled (bool) : Indicates whether missing/null values \n",
    "            in the label/feature data were filled\n",
    "        fill_val (None/float) : Value used to fill the null values when \n",
    "            missing_val_filled==True, default None            \n",
    "\n",
    "    Returns:\n",
    "        X_known.index : index corresponding to known ratings\n",
    "        X_missing.index : index corresponding to missing/unknown ratings\n",
    "    \"\"\"    \n",
    "    if missing_val_filled:\n",
    "        if fill_val is None:\n",
    "            missing_vals = (label_data == 0).values.flatten()\n",
    "        else:\n",
    "            missing_vals = (label_data == fill_val).values.flatten()\n",
    "    else:\n",
    "        missing_vals = label_data.isnull().values.flatten()\n",
    "    if split_axis == 1:\n",
    "        X_missing = feature_data.loc[missing_vals, :]\n",
    "        X_known = feature_data.loc[~missing_vals, :]\n",
    "    elif split_axis == 0:\n",
    "        X_missing = feature_data.loc[:, missing_vals]\n",
    "        X_known = feature_data.loc[:, ~missing_vals]\n",
    "    else:\n",
    "        X_missing = feature_data.loc[missing_vals, :]\n",
    "        X_known = feature_data.loc[~missing_vals, :]\n",
    "\n",
    "    return X_known.index, X_missing.index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def known_missing_split_U(U, split_axis=1, missing_val_filled=False,\n",
    "                          fill_val=None):\n",
    "    \"\"\"Returns index of the dataset corresponding to known and missing ratings\n",
    "    in for the whole utility matrix\n",
    "\n",
    "        Parameters:\n",
    "                U_df (DataFrame) : utility matrix (rows are users, columns are items) \n",
    "                split_axis (int) : The axis along the utility matrix is split, \n",
    "                    {0/'index', 1/'columns'}, default 1\n",
    "                missing_val_filled (bool) : Indicates whether missing/null \n",
    "                    values in the label/feature data were filled\n",
    "                fill_val (None/float) : Value used to fill the null values when \n",
    "                    missing_val_filled==True, default None            \n",
    "\n",
    "        Returns:\n",
    "                known_idx (dict): keys are the column name/index to be predicted, \n",
    "                    values are index of utility matrix that contains known values\n",
    "                missing_idx (dict): keys are the column name/index to be predicted, \n",
    "                    values are index of utility matrix that contains missing values\n",
    "        \"\"\"    \n",
    "    \n",
    "    if missing_val_filled:\n",
    "        if fill_val is None:\n",
    "            missing_val = 0\n",
    "        else:\n",
    "            missing_val = fill_val\n",
    "        if split_axis == 1:\n",
    "            known_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "        elif split_axis == 0:\n",
    "            known_idx = dict((U == missing_val).apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.T.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).apply(lambda x: np.array(x), axis=1).apply(\n",
    "                lambda x: U.T.index[np.argwhere(x).flatten()]))\n",
    "        else:\n",
    "            print('Invalid axis. Result for axis=1 is returned.')\n",
    "            known_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict((U == missing_val).T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "    else:\n",
    "        if split_axis == 1:\n",
    "            known_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "        elif split_axis == 0:\n",
    "            train_idx = dict(U.isnull().apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.T.index[np.argwhere(~x).flatten()]))\n",
    "            test_idx = dict(U.isnull().apply(lambda x: np.array(x), axis=1).apply(\n",
    "                lambda x: U.T.index[np.argwhere(x).flatten()]))\n",
    "        else:\n",
    "            print('Invalid axis. Result for axis=1 is returned.')\n",
    "            known_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(~x).flatten()]))\n",
    "            missing_idx = dict(U.isnull().T.apply(lambda x: np.array(\n",
    "                x), axis=1).apply(lambda x: U.index[np.argwhere(x).flatten()]))\n",
    "\n",
    "    return known_idx, missing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>97</th>\n",
       "      <th>141</th>\n",
       "      <th>227</th>\n",
       "      <th>260</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>344</th>\n",
       "      <th>370</th>\n",
       "      <th>...</th>\n",
       "      <th>89745</th>\n",
       "      <th>96448</th>\n",
       "      <th>98160</th>\n",
       "      <th>102125</th>\n",
       "      <th>106782</th>\n",
       "      <th>112552</th>\n",
       "      <th>122916</th>\n",
       "      <th>136834</th>\n",
       "      <th>142448</th>\n",
       "      <th>158238</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  22      25      97      141     227     260     281     282     \\\n",
       "user_id                                                                   \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  344     370     ...  89745   96448   98160   102125  106782  112552  \\\n",
       "user_id                  ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  122916  136834  142448  158238  \n",
       "user_id                                  \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "6           NaN     NaN     NaN     NaN  \n",
       "16          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "42          NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "597         NaN     NaN     NaN     NaN  \n",
       "600         NaN     NaN     NaN     NaN  \n",
       "603         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[81 rows x 98 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>97</th>\n",
       "      <th>141</th>\n",
       "      <th>227</th>\n",
       "      <th>260</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>344</th>\n",
       "      <th>370</th>\n",
       "      <th>...</th>\n",
       "      <th>89745</th>\n",
       "      <th>96448</th>\n",
       "      <th>98160</th>\n",
       "      <th>102125</th>\n",
       "      <th>106782</th>\n",
       "      <th>112552</th>\n",
       "      <th>122916</th>\n",
       "      <th>136834</th>\n",
       "      <th>142448</th>\n",
       "      <th>158238</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  22      25      97      141     227     260     281     282     \\\n",
       "user_id                                                                   \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  344     370     ...  89745   96448   98160   102125  106782  112552  \\\n",
       "user_id                  ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "597         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "600         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "603         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  122916  136834  142448  158238  \n",
       "user_id                                  \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "6           NaN     NaN     NaN     NaN  \n",
       "16          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "42          NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "597         NaN     NaN     NaN     NaN  \n",
       "600         NaN     NaN     NaN     NaN  \n",
       "603         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[81 rows x 98 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_df_mc = mean_center_utilmat(re.utility_matrix, axis=1, fillna=False)\n",
    "U_df_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_index, missing_index = known_missing_split_U(\n",
    "    U=U_df_mc, split_axis=1, missing_val_filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:20.000940Z",
     "start_time": "2021-09-23T02:16:19.993558Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def nan_mask(p=0.2):\n",
    "    \"\"\"Randomly sets values of the utility matrix to NaN\n",
    "    \n",
    "    Parameters:\n",
    "            U (numpy.array): utility matrix (rows are users, columns are items) \n",
    "            p (float): percentage of matrix which will be set to NaN, \n",
    "                value ranges from 0 to 1, default 0.2\n",
    "\n",
    "    Returns:\n",
    "            U*mask (numpy.array): utility matrix masked with NaNs\n",
    "    \"\"\"    \n",
    "    # VARS\n",
    "    U = self.utility_matrix\n",
    "    \n",
    "    mask = np.ones(np.shape(U))\n",
    "    random_index = np.random.choice(U.size, size=int(U.size*p), replace=False)\n",
    "    np.ravel(mask)[random_index] = np.nan\n",
    "    return U*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:20.585119Z",
     "start_time": "2021-09-23T02:16:20.577003Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def gen_missing_ratings(U_df, p=0.2, n_masks=10):\n",
    "    \"\"\"Generates multiple sets of masked utility matrix \n",
    "    \n",
    "    Parameters:\n",
    "            U_df (DataFrame): utility matrix (rows are users, columns are items) \n",
    "            p (float): percentage of matrix which will be set to NaN, \n",
    "                value ranges from 0 to 1, default 0.2\n",
    "            n_masks (int): number of masks to be generated; indicates number \n",
    "                of synthetic datasets to be generated, default 10\n",
    "\n",
    "    Returns:\n",
    "            masked_um (list): list of masked utility matrices\n",
    "    \"\"\"    \n",
    "    cols = U_df.columns\n",
    "    idx = U_df.index\n",
    "    U_arr = U_df.values\n",
    "    masked_um = []\n",
    "    for n in range(n_masks):\n",
    "        masked_um.append(pd.DataFrame(nan_mask(U_arr, p=p),\n",
    "                                      columns=cols,\n",
    "                                      index=idx))\n",
    "    return masked_um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-clustered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:27.255608Z",
     "start_time": "2021-09-23T02:16:27.226208Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_models_itemwise(U, model, suffix='model'):\n",
    "    \"\"\"Initializes classifier/regressor per item to be predicted\n",
    "\n",
    "    Parameters:\n",
    "        model : model object to use to fit the data\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        suffix (str) : suffix for keys in output dictionary\n",
    "\n",
    "    Returns:\n",
    "        models (dict): dictionary of models, keys correspond to columns/items \n",
    "        in the utility matrix and values are the model objects\n",
    "    \"\"\"\n",
    "    models = {f'{item}{suffix}': model for item in U.columns}\n",
    "    return models\n",
    "\n",
    "\n",
    "def initialize_models_userwise(U, model, suffix='_model'):\n",
    "    \"\"\"Initializes classifier/regressor per user to be predicted\n",
    "\n",
    "    Parameters:\n",
    "        model : model object to use to fit the data\n",
    "        U (DataFrame) : utilily matrix (rows are users, columns are items) \n",
    "        suffix (str) : suffix for keys in output dictionary\n",
    "\n",
    "    Returns:\n",
    "        models (dict): dictionary of models, keys correspond to the rows/users \n",
    "            in the utility matrix and values are the model objects\n",
    "    \"\"\"\n",
    "\n",
    "    models = {f'{user}{suffix}': model for user in U.index}\n",
    "    return models\n",
    "\n",
    "\n",
    "def eval_convergence_criterion(\n",
    "        pred_curr, pred_prev, stopping_criterion='mse',\n",
    "        mse_threshold=0.1, stdev_threshold=None,\n",
    "        scaled=False, scaling_method='max',\n",
    "        rating_min=None, rating_max=None):\n",
    "    \"\"\"\n",
    "    Evaluates whether the model training has converged\n",
    "\n",
    "    Parameters:\n",
    "        pred_curr (array) : array of predicted ratings from current iteration\n",
    "        pred_prev (array) : array of predicted ratings from previous iteration\n",
    "        stopping_criterion (str) : metric for evaluating convergence, \n",
    "            {mse/'mean squared error', stdev_abs/'standard deviation of \n",
    "            absolute difference'}, default 'mse'\n",
    "        mse_threshold (float) : threshold for stopping criterion when \n",
    "            'mse'is selected, default 0.1            \n",
    "        stdev_threshold (float) : threshold for stopping criterion when \n",
    "            'stdev_abs'is selected, default None\n",
    "        scaled (bool) : Indicates whether metric for stopping criterion is \n",
    "            to be scaled/normalized\n",
    "        scaling_method (str) : indicates method for scaling when scaled==True, \n",
    "            {max/'maximum rating', minmax/'maximum rating - minimum rating'},\n",
    "            default 'max'\n",
    "        rating_min (numeric) : minimum value of rating, default None\n",
    "        rating_max (numeric) : maximum value of rating, default None\n",
    "\n",
    "    Returns:\n",
    "        metric (float) : value of metric\n",
    "        stop_train (bool) : Indicates convergence (stop training when True)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if stopping_criterion == 'mse':\n",
    "        if mse_threshold is None:\n",
    "            print('Threshold for calculating MSE is not defined. '\n",
    "                  'Input threshold value.')\n",
    "        metric = mean_squared_error(pred_curr, pred_prev)\n",
    "\n",
    "        if scaled:\n",
    "            if scaling_method == 'max':\n",
    "                if rating_max is None:\n",
    "                    print('Scaled metric needs maximum possible value '\n",
    "                          'of rating.')\n",
    "                else:\n",
    "                    scaling_factor = rating_max\n",
    "            elif scaling_metho == 'minmax':\n",
    "                if (rating_max is None) or (rating_min is None):\n",
    "                    print(\n",
    "                        'Scaled metric needs maximum and minimum '\n",
    "                        'possible values of rating.')\n",
    "                else:\n",
    "                    scaling_factor = (rating_max - rating_min)\n",
    "            metric /= scaling_factor\n",
    "\n",
    "        stop_train = (metric <= mse_threshold)\n",
    "\n",
    "    elif stopping_criterion == 'stdev_abs':\n",
    "        if stdev_threshold is None:\n",
    "            print('Threshold for calculating standard deviation of absolute '\n",
    "                  'error is not defined. Input threshold value.')\n",
    "\n",
    "        metric = np.std(np.abs(pred_curr-pred_prev))\n",
    "\n",
    "        if scaled:\n",
    "            if scaling_method == 'max':\n",
    "                if rating_max is None:\n",
    "                    print('Scaled metric needs maximum possible value '\n",
    "                          'of rating.')\n",
    "                else:\n",
    "                    scaling_factor = rating_max\n",
    "            elif scaling_metho == 'minmax':\n",
    "                if (rating_max is None) or (rating_min is None):\n",
    "                    print(\n",
    "                        'Scaled metric needs maximum and minimum possible'\n",
    "                        ' values of rating.')\n",
    "                else:\n",
    "                    scaling_factor = (rating_max - rating_min)\n",
    "            metric /= scaling_factor\n",
    "\n",
    "        stop_train = (metric <= stdev_threshold)\n",
    "\n",
    "    else:\n",
    "        if mse_threshold is None:\n",
    "            print('Stopping criterion set to MSE. Input threshold value.')\n",
    "        metric = mean_squared_error(pred_curr, pred_prev)\n",
    "\n",
    "        stop_train = (metric <= mse_threshold)\n",
    "\n",
    "    return metric, stop_train\n",
    "\n",
    "\n",
    "def train_model_itemwise(\n",
    "        U_df, model_object, return_models=True, max_iter=100,\n",
    "        stopping_criterion='mse', mse_threshold=0.1, stdev_threshold=None,\n",
    "        scaled=False, scaling_method='max', rating_min=None, rating_max=None):\n",
    "    \"\"\"Trains model iteratively for the item-wise recommender system: \n",
    "    (1) Estimates the missing entries of each column/item by setting it as \n",
    "    the target variable and the remaining columns as the feature variables. \n",
    "    (2) For the remaining columns, the current set of filled in values are \n",
    "    used to create a complete matrix of feature variables. \n",
    "    (3) The observed ratings in the target column are used for training. \n",
    "    (4) The missing entries are updated based on the prediction of the model \n",
    "    on each target column. \n",
    "\n",
    "        Parameters:\n",
    "                U_df (DataFrame): raw utility matrix (rows are users, \n",
    "                    columns are items) \n",
    "                model_object : model object to use to fit the data\n",
    "                return_models (bool): Indicates whether trained models are \n",
    "                    returned as output, default True\n",
    "                max_iter (int): maximum number of iterations for model \n",
    "                    training and updating of missing values, default 100\n",
    "                stopping_criterion (str): metric for evaluating convergence, \n",
    "                    {mse/'mean squared error', stdev_abs/'standard deviation \n",
    "                    of absolute difference'}, default 'mse'\n",
    "                mse_threshold (float): threshold for stopping criterion when \n",
    "                    'mse'is selected, default 0.1            \n",
    "                stdev_threshold (float): threshold for stopping criterion \n",
    "                    when 'stdev_abs'is selected, default None\n",
    "                scaled (bool): Indicates whether metric for stopping criterion \n",
    "                    is to be scaled/normalized\n",
    "                scaling_method (str): indicates method for scaling when \n",
    "                    scaled==True, {max/'maximum rating',\n",
    "                    minmax/'maximum rating - minimum rating'}, default 'max'\n",
    "                rating_min (numeric): minimum value of rating, default None\n",
    "                rating_max (numeric): maximum value of rating, default None\n",
    "\n",
    "        Returns:\n",
    "                U_update (DataFrame): complete utility matrix\n",
    "                metric_iter (array-like): value of convergence metric per iteration\n",
    "                models_item (dict): dictionary of trained models, returned only if\n",
    "                    return_models=True\n",
    "    \"\"\"\n",
    "    # VARS\n",
    "    U = U_df.copy()\n",
    "\n",
    "    models_item = initialize_models_itemwise(\n",
    "        model=model_object, U=U, suffix='')\n",
    "\n",
    "    known_index, missing_index = known_missing_split_U(\n",
    "        U=U, split_axis=1, missing_val_filled=True)\n",
    "\n",
    "    len_missing_vals = len(sum([i.tolist()\n",
    "                                for i in missing_index.values()], []))\n",
    "    \n",
    "    U = mean_center_utilmat(U, axis=1, fillna=True, fill_val=0)\n",
    "    U_update = U.copy()    \n",
    "    \n",
    "    preds_per_iter = [np.zeros(len_missing_vals)]\n",
    "    metric_iter = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        preds = []\n",
    "        for item in U.columns:\n",
    "            models_item[str(item)].fit(\n",
    "                U_update.drop(item, axis=1).loc[known_index[item]],\n",
    "                U_update.loc[known_index[item], item])\n",
    "            if len(missing_index[item]) > 0:\n",
    "                pred = models_item[str(item)].predict(\n",
    "                    U_update.drop(item, axis=1).loc[missing_index[item]])\n",
    "            else:\n",
    "                pred = np.array([])\n",
    "            preds.append(pred)\n",
    "            U_update.loc[missing_index[item], item] = pred\n",
    "\n",
    "        metric, stopping_criterion = eval_convergence_criterion(\n",
    "            np.hstack(preds),\n",
    "            preds_per_iter[-1],\n",
    "            stopping_criterion=stopping_criterion,\n",
    "            mse_threshold=mse_threshold,\n",
    "            stdev_threshold=stdev_threshold,\n",
    "            scaled=scaled,\n",
    "            scaling_method=scaling_method,\n",
    "            rating_min=rating_min,\n",
    "            rating_max=rating_min)\n",
    "        metric_iter.append(metric)\n",
    "        if stopping_criterion:\n",
    "            break\n",
    "        preds_per_iter.append(np.hstack(preds))\n",
    "\n",
    "    if return_models:\n",
    "        return U_update, metric_iter, models_item\n",
    "    else:\n",
    "        return U_update, metric_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.classifier import Random\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "mlp1 = MLPRegressor(hidden_layer_sizes=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'22': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '25': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '97': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '141': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '227': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '260': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '281': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '282': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '344': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '370': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '380': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '431': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '475': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '520': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '589': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '718': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '761': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '818': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '899': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1016': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1035': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1064': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1073': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1206': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1225': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1231': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1244': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1270': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1285': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1291': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1344': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1381': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1580': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1610': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1690': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1693': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1699': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1892': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '1997': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2028': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2114': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2166': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2231': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2248': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2268': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2321': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2406': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2490': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2571': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2616': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2651': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2731': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2762': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '2997': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3479': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3535': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3826': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '3861': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4022': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4306': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4848': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4855': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4896': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '4963': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5254': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5266': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5451': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '5952': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '6287': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '6377': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '6539': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7160': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7323': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '7373': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '8376': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '8983': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '26578': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '27746': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '27773': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '34162': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '46578': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '51662': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '58998': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '66665': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '67408': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '74946': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '78349': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '79702': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '89745': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '96448': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '98160': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '102125': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '106782': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '112552': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '122916': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '136834': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '142448': MLPRegressor(hidden_layer_sizes=(100, 100)),\n",
       " '158238': MLPRegressor(hidden_layer_sizes=(100, 100))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = U_df_mc.copy()\n",
    "model_object = mlp1\n",
    "\n",
    "models_item = initialize_models_itemwise(U, model_object, suffix='')\n",
    "models_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>97</th>\n",
       "      <th>141</th>\n",
       "      <th>227</th>\n",
       "      <th>260</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>344</th>\n",
       "      <th>370</th>\n",
       "      <th>...</th>\n",
       "      <th>89745</th>\n",
       "      <th>96448</th>\n",
       "      <th>98160</th>\n",
       "      <th>102125</th>\n",
       "      <th>106782</th>\n",
       "      <th>112552</th>\n",
       "      <th>122916</th>\n",
       "      <th>136834</th>\n",
       "      <th>142448</th>\n",
       "      <th>158238</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  22      25      97      141     227     260     281     282     \\\n",
       "user_id                                                                   \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  344     370     ...  89745   96448   98160   102125  106782  112552  \\\n",
       "user_id                  ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "16          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "20          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "42          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "item_id  122916  136834  142448  158238  \n",
       "user_id                                  \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "6           NaN     NaN     NaN     NaN  \n",
       "16          NaN     NaN     NaN     NaN  \n",
       "20          NaN     NaN     NaN     NaN  \n",
       "42          NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "U_imputed, metrics, models = train_model_itemwise(U, model_object, return_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_imputed.add(U_df.mean(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_imputed.add(U_df.mean(axis=1), axis=0).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly get an item from the item clusters\n",
    "top_k # top items\n",
    "\n",
    "# randomly select items randomly from top cluster: number of items in the cluster\n",
    "# if there's any spillover, randomly get from the next top cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_users(self, model):\n",
    "    \"\"\"\n",
    "    Perform user-wise clustering and assign each user to a cluster.\n",
    "    \n",
    "    Paramters\n",
    "    ---------                  \n",
    "    model        : an sklearn model object\n",
    "                   An object with a fit_predict method. Used to cluster the\n",
    "                   users into groups with similar ratings of items.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model         : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    clusters of users from fname\n",
    "    \n",
    "    result        : dict\n",
    "                    A mapping of each user's cluster with the keys being the\n",
    "                    user_id and the values their cluster membership\n",
    "    \n",
    "    df            : pandas DataFrame\n",
    "                    Utility matrix derived from fname with the final column\n",
    "                    corresponding to the cluster membership of that user\n",
    "    \"\"\"\n",
    "\n",
    "    # SOME VARIABLES\n",
    "    df = self.utility_matrix # utility matrix    \n",
    "    df = df.fillna(0) # fillna with 0\n",
    "    \n",
    "    # Aggregation through tables\n",
    "    u_clusterer = model\n",
    "    u_predict = u_clusterer.fit_predict(df)\n",
    "    df['u_cluster'] = u_predict\n",
    "\n",
    "    model = u_clusterer\n",
    "    result = dict(df['u_cluster'])\n",
    "    \n",
    "    # Output variables\n",
    "    self.user_cluster_model = model # attach the user_cluster_model to the class\n",
    "    self.utility_matrix_w_user_clusters = df # utility matrix with user clusters\n",
    "    self.user_cluster_mapping_dict = result # mapping of users and cluster labels\n",
    "    self.users_clustered = True # tag that we clustered the users\n",
    "    \n",
    "    return model, result, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_items(self, model):\n",
    "    \n",
    "    # WE MIGHT WANT TO FIX TO DROP COLS AS HARD CODED INSTEAD OF AN ARGUMENT\n",
    "    # SO LONG AS WE STANDARDIZE THE INPUT\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform item-wise clustering and assign each item to a cluster of similar\n",
    "    items based on the users that \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "                   \n",
    "    model        : an sklearn model object\n",
    "                   An object with a fit_predict method. Used to cluster the\n",
    "                   users into groups with similar ratings of items.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model         : an sklearn model object\n",
    "                    The fitted version of the model input used to predict the\n",
    "                    clusters of items from fname\n",
    "    \n",
    "    result        : dict\n",
    "                    A mapping of each item's cluster with the keys being the\n",
    "                    item_id and the values their cluster membership\n",
    "    \n",
    "    df_items      : pandas DataFrame\n",
    "                    Utility matrix derived from fname with the final column\n",
    "                    corresponding to the cluster membership of that item\n",
    "    \"\"\"\n",
    "\n",
    "    # SOME VARIABLES\n",
    "    df = self.utility_matrix # utility matrix      \n",
    "    df = self.utility_matrix # utility matrix    \n",
    "    df = df.fillna(0) # fillna with 0\n",
    "\n",
    "    df_items = df.T\n",
    "    i_clusterer = model\n",
    "\n",
    "    i_predict = i_clusterer.fit_predict(df_items)\n",
    "    df_items['i_cluster'] = i_predict\n",
    "\n",
    "    model = i_clusterer\n",
    "    result = dict(df_items['i_cluster'])\n",
    "    \n",
    "    # Output variables\n",
    "    self.item_cluster_model = model # attach the item_cluster_model to the class\n",
    "    self.utility_matrix_w_item_clusters = df_items # utility matrix with item clusters\n",
    "    self.item_cluster_mapping_dict = result # mapping of users and cluster labels    \n",
    "    self.items_clustered = True # tag that we clustered the items\n",
    "    \n",
    "    return model, result, df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_users = KMeans(n_clusters=10)\n",
    "km_items = KMeans(n_clusters=10)\n",
    "\n",
    "user_model, user_cluster_map, util_matrix_w_users = re.cluster_users(km_users)\n",
    "item_model, item_cluster_map, util_matrix_w_items = re.cluster_items(km_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.item_cluster_model, re.user_cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_w_user_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_w_item_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def cluster_assignment(self):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts the dictionary containing user_id and user_cluster assignment  \n",
    "    to a pandas data frame \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result        : dataframe of cluster assignments\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if self.users_clustered: # if we ran the cluster_users method: \n",
    "        data_name='user_id'        \n",
    "        cluster_name='u_cluster'        \n",
    "        self.user_assignment = pd.DataFrame(list(self.user_cluster_mapping_dict.items()), columns=[data_name, cluster_name])\n",
    "        self.user_assignment.set_index(data_name, inplace=True)\n",
    "        \n",
    "    if self.items_clustered: # if we ran the cluster_users method: \n",
    "        data_name='user_id'        \n",
    "        cluster_name='i_cluster'        \n",
    "        self.item_assignment = pd.DataFrame(list(self.item_cluster_mapping_dict.items()), columns=[data_name, cluster_name])\n",
    "        self.item_assignment.set_index(data_name, inplace=True)        \n",
    "    \n",
    "    return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.cluster_assignment()\n",
    "re.user_assignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.item_assignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "\n",
    "def utility_matrix_agg(self, u_agg='mean', i_agg='mean'):\n",
    "    \"\"\"\n",
    "    Aggregates the results of the clustering with respect to item clusters and user clusters.\n",
    "    ------\n",
    "    Methods : two possible ways to aggregate the results of cluster assignments in df_u and df_i are 'sum' and 'mean'\n",
    "    u_agg   : aggregration method to be used for users\n",
    "    \n",
    "    i_agg   : aggregation method to be used for items\n",
    "    \n",
    "    -----\n",
    "    Returns : utility matrix consisting of the aggregrated user clusters as rows and aggregated item clusters as columns\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # GET utility matrices with cluster labels\n",
    "    df_u = self.utility_matrix_w_user_clusters\n",
    "    df_i = self.utility_matrix_w_item_clusters\n",
    "\n",
    "    u_series = df_u['u_cluster']\n",
    "    i_series = df_i['i_cluster']\n",
    "\n",
    "    u_ids = np.unique(u_series.values)\n",
    "    i_ids = np.unique(i_series.values) \n",
    "\n",
    "    u_feats = {}\n",
    "    for u_id in u_ids: #u_ids are clusters of u_id\n",
    "        sub_df = df_u.groupby('u_cluster').get_group(\n",
    "            u_id).drop(columns=['u_cluster']).T\n",
    "        sub_df = sub_df.merge(i_series.reset_index(drop=True), left_index=True, right_index=True)\n",
    "\n",
    "        if u_agg == 'sum':\n",
    "            df_grp = sub_df.groupby('i_cluster').sum()\n",
    "        if u_agg == 'mean':\n",
    "            df_grp = sub_df.groupby('i_cluster').mean()\n",
    "        if not isinstance(u_agg,str):\n",
    "            df_grp = sub_df.groupby('i_cluster').apply(u_agg)\n",
    "\n",
    "        if i_agg == 'sum':\n",
    "            df_grp = df_grp.sum(axis=1)\n",
    "        if i_agg == 'mean':\n",
    "            df_grp = df_grp.mean(axis=1)\n",
    "        if not isinstance(i_agg,str):\n",
    "            df_grp = df_grp.apply(i_agg, axis=1)\n",
    "\n",
    "        u_feats[u_id] = df_grp\n",
    "    \n",
    "\n",
    "    u_matrix = pd.DataFrame()\n",
    "    for k, v in u_feats.items():\n",
    "        u_matrix = u_matrix.merge(v.rename(k), how='outer',\n",
    "                                  left_index=True, right_index=True)\n",
    "\n",
    "    # UPDATE THE UTILITY MATRIX\n",
    "    self.utility_matrix = u_matrix.fillna(0).T \n",
    "    self.utility_matrix.index.rename('u_cluster', inplace=True)\n",
    "    return self.utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.utility_matrix_agg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:28.922441Z",
     "start_time": "2021-09-23T02:16:28.912421Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def train_model_itemwise_cluster(\n",
    "        Uc_df, model_object, n_synth_data=100, p=0.2):\n",
    "    \"\"\"Trains model iteratively for the cluster-based recommender system: \n",
    "    (1) Given cluster-based utility matrix, create multiple synthetic data of \n",
    "    missing ratings. Randomly drop matrix elements by setting them to NaN to \n",
    "    create \"missing\" ratings. \n",
    "    (2) For each set of synthetic data:\n",
    "        (2a) Estimate the missing entries of each column/item by setting it as \n",
    "        the target variable and the remaining columns as the feature variables. \n",
    "        (2b) For the remaining columns, the current set of filled in values are \n",
    "        used to create a complete matrix of feature variables. \n",
    "        (2c) The observed ratings in the target column are used for training. \n",
    "        (2d) The missing entries are updated based on the prediction of the \n",
    "        model on each target column. \n",
    "    (3) Get mean of the completed utility matrix from all imputed synthetic data. \n",
    "\n",
    "    Parameters:\n",
    "            Uc_df (DataFrame): output utility matrix from clustering\n",
    "                (rows are users, columns are items) \n",
    "            model_object: model object to use to fit the data\n",
    "            n_synth_data (int): number of synthetic datasets to be generated,\n",
    "                default 100\n",
    "            p (float): percentage of matrix which will be set to NaN, \n",
    "                value ranges from 0 to 1, default 0.2         \n",
    "\n",
    "    Returns:\n",
    "            (DataFrame): updated cluster-based utility matrix \n",
    "\n",
    "    \"\"\"\n",
    "    synth_data = gen_missing_ratings(Uc_df, p=p, n_masks=n_synth_data)\n",
    "    um_output = []\n",
    "    for n in range(n_synth_data):\n",
    "        U_df = synth_data[n]\n",
    "        U_df_mc = um.mean_center_utilmat(U_df, axis=1, fillna=True, fill_val=0)\n",
    "        U_imputed, metrics, models = im.train_model_itemwise(\n",
    "            U_df_mc, model_object, return_models=return_models)\n",
    "        um_output.append(U_imputed)\n",
    "    um_output = pd.concat(um_output)\n",
    "    return um_output.groupby(um_output.index).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:16:32.043058Z",
     "start_time": "2021-09-23T02:16:32.030948Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def get_rec(utility_matrix, utility_matrix_o, user_list, top_n, uc_assignment=None):\n",
    "    \n",
    "    \"\"\"Returns the top N item cluster recommendations for each user in the user list\n",
    "    \n",
    "            Parameters:\n",
    "                    utility_matrix (numpy.ndarray): Matrix of utilities for each user-item pairing\n",
    "                    utility_matrix_o (numpy.ndarray): Original utility matrix, before imputation\n",
    "                    user_list (array-like): List of users\n",
    "                    uc_assignment (array-like): List containing the cluster assignment of each user\n",
    "                    top_n (int): Number of item clusters to recommend\n",
    "\n",
    "            Returns:\n",
    "                    df_rec (pandas.DataFrame): Table containing the top N item cluster recommendations for each user in the user list\n",
    "                    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Don't recommend items that are already rated\n",
    "    utility_matrix[np.where(utility_matrix_o != 0)] = -np.inf\n",
    "    \n",
    "    # Get top N per user cluster\n",
    "    cluster_rec = utility_matrix.argsort()[:, -top_n:]\n",
    "\n",
    "    # Create recommendation table\n",
    "    df_rec = pd.DataFrame()\n",
    "    df_rec['user_id'] = user_list\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        df_rec['rank_'+str(i+1)] = np.zeros(df_rec.shape[0])\n",
    "        for j in range(df_rec.shape[0]):\n",
    "            if uc_assignment is None:\n",
    "                df_rec.iloc[j, i+1] = cluster_rec[user_list[j], top_n-i-1]\n",
    "            else:\n",
    "                df_rec.iloc[j, i+1] = cluster_rec[uc_assignment[user_list[j]], top_n-i-1]\n",
    "                \n",
    "    return df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to Resype\n",
    "def get_rec_item(df_rec, top_k, ic_assignment):\n",
    "    \n",
    "    \"\"\"Returns the top K item recommendations for each user in the user list. \n",
    "    Items are selected randomly from the top recommended item cluster, exhaustively. Left overs are taken from the next highest ranked item clusters in a cascading fashion.\n",
    "    \n",
    "            Parameters:\n",
    "                    df_rec (pandas.DataFrame): Table containing the top N item cluster recommendations for each user in the user list\n",
    "                    ic_assignment (array-like): List containing the cluster assignment of each item\n",
    "                    top_n (int): Number of items to recommend\n",
    "\n",
    "            Returns:\n",
    "                    df_rec_item (pandas.DataFrame): Table containing the top K item recommendations for each user in the user list\n",
    "                    \n",
    "    \"\"\"\n",
    "\n",
    "    # Create recommendation table\n",
    "    df_rec_item = pd.DataFrame()\n",
    "    df_rec_item['user_id'] = df_rec['user_id']\n",
    "    \n",
    "    for i in range(top_k):\n",
    "        df_rec_item['rank_'+str(i+1)] = np.zeros(df_rec_item.shape[0])\n",
    "        \n",
    "    #for j in range(df_rec_item.shape[0]):\n",
    "    #    df_rec_item.iloc[j, i+1] = \n",
    "                \n",
    "    return df_rec_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the entire pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Clustering Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature = joblib.load(\"tmp_files/user_feature\")\n",
    "item_feature_table = joblib.load(\"tmp_files/item_feature_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:20:12.741547Z",
     "start_time": "2021-09-23T02:17:57.273618Z"
    }
   },
   "outputs": [],
   "source": [
    "x_u, y_u, df_u = u_cluster(user_feature,\"kmeans\", u_clusters=10)\n",
    "x_i, y_i, df_i = i_cluster(item_feature_table,'kmeans', i_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:20:12.759368Z",
     "start_time": "2021-09-23T02:20:12.747847Z"
    }
   },
   "outputs": [],
   "source": [
    "uc_assignment = cluster_assignment(y_u, data_name='user_id')\n",
    "ic_assignment = cluster_assignment(y_i, data_name='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ic_assignment.head(3))\n",
    "display(uc_assignment.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_u.head(3))\n",
    "display(df_i.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T02:52:24.073789Z",
     "start_time": "2021-09-23T02:52:23.591329Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Uc = utility_matrix_agg(df_u, df_i, u_agg='sum', i_agg='sum')\n",
    "Uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(Uc, \"tmp_files/Uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uc = joblib.load(\"tmp_files/Uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "mlp1 = MLPRegressor(hidden_layer_sizes=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we can prob make the model an argument of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Uc_df_output = train_model_itemwise_cluster(Uc, n_synth_data=20, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install resype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "# Francis to change the values to be the ratings e.g. 1,2,3,4,5\n",
    "# Francis to remove scaling\n",
    "\n",
    "# RESYPE PIPE\n",
    "re = resype(transaction_list, user_features, item_features)\n",
    "km = Kmeans(**params)\n",
    "re.cluster_fit(user_model=km, item_model=None, user_n=20, item_n=None, agg_func='sum')\n",
    "# Gilbert will update the function so it looks like the thing above\n",
    "\n",
    "# internal logic na self.is_clustered = True / False\n",
    "# if self.is_clustered, run the model for clustered UM, else run the model for unclustered\n",
    "ml = GBM(**params)\n",
    "re.fit(model=ml, method=\"iterative or svd\") \n",
    "# Eloi will update the model for clustered version\n",
    "# Eloi and Vinni will add iterative or svd logic\n",
    "# Eloi to add logic if ratings are 0s and 1s and with NaN - autodetect if just 0 and 1\n",
    "\n",
    "df_rec = re.get_rec(top_k=10, user_list = [1, 2, 3]) # Basti will update the logic for unclustered version\n",
    "\n",
    "# get_rec should assign for users not yet in the training set\n",
    "# limitation of the collaborative filtering model\n",
    "\n",
    "# Basti to prepare the Getting started\n",
    "# Gilbert to help with documentation after fixing the function\n",
    "# Francis to help with the documentation - if we need to do anything else\n",
    "# Issa to help with documentation - if we need to do anything else\n",
    "# Prince to compile to classes and prepare the website doc\n",
    "# Separate the functions -> 1 function is to 1 notebook. Show input and show output per function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules, methods, arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item=1\n",
    "fig, ax = plt.subplots(1)\n",
    "Uc[item].plot(label='original')\n",
    "Uc_df_output[item].plot(label='model_output')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
