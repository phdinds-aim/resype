{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371cddf5-b4ec-4489-a4df-11fe9bf3bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(text):\n",
    "    ''' Preprocess text for tf-idf\n",
    "    \n",
    "    Transforms the text into lowercase and removes symbols\n",
    "    and punctuations\n",
    "    Removes stopwords using NLTK library\n",
    "    Lemmatizes words using SnowballStemmer (NLTK Library)\n",
    "    \n",
    "    Input\n",
    "    --------\n",
    "    text (string) :  string from the Movielens synopsis dataset \n",
    "    \n",
    "    \n",
    "    Output\n",
    "    --------\n",
    "    new_text (string)  : preprocessed text for further tf-idf processing\n",
    "    \n",
    "    '''\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.snowball import SnowballStemmer # get from VP later\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    new_text = \"\"\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        if word not in stop_words and len(word) > 2:\n",
    "            new_text = new_text + \" \" + stemmer.stem(word)\n",
    "    \n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c46499-0493-44a6-9b59-e727f0a7cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_feature(num_features = 300):\n",
    "    '''\n",
    "    Return item_feature matrix based on TF-IDF of Movie Synopsis\n",
    "    \n",
    "    Takes in the list of movies that has been rated in the MovieLens 100k\n",
    "    dataset and fetches the respective synopsis for TF-IDF computation\n",
    "    \n",
    "       \n",
    "    Input\n",
    "    ---------\n",
    "    num_features : number of features to be used for the TF-IDF extraction\n",
    "                 : default value 300 (~sqrt[100k rows])\n",
    "    \n",
    "    \n",
    "    Output\n",
    "    ---------\n",
    "    item_feature (pd.DataFrame): feature_vector from TF-IDF extracted\n",
    "                            from movie synopses the TheMovieDB dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    transaction_list = pd.read_csv('ratings.csv', usecols=['movieId'])\n",
    "    \n",
    "    # filter the unique movie IDs\n",
    "    seen_movies = pd.DataFrame(transaction_list['movieId'].unique(), columns={'movieId'})\n",
    "    \n",
    "    # the synopsis is based on the \"The Movie DB\" Id system\n",
    "    # links.csv has a mapping between MovieLens ID and The MovieDB Id\n",
    "    movie_id_links = pd.read_csv('links.csv', usecols =['movieId','tmdbId'])\n",
    "    movie_id_links = movie_id_links.dropna()\n",
    "    movie_id_links.head()\n",
    "    \n",
    "    # get mapping between MovieLens IDs and TMDB IDs\n",
    "    seen_movies = seen_movies.merge(movie_id_links, on='movieId', how='inner')\n",
    "    \n",
    "    # Read MetaData CSV file with movie plots/synopsis\n",
    "    metadata = pd.read_csv('movies_metadata.csv', usecols=['id','overview'])\n",
    "    metadata = metadata.rename(columns={'id':'tmdbId'})\n",
    "\n",
    "    # drop movies with invalid tmbdId (e.g., date string instead of integer)\n",
    "    ids1 = pd.to_numeric(metadata['tmdbId'], errors='coerce').isna()\n",
    "    metadata = metadata.drop(metadata[ids1].index)\n",
    "\n",
    "    # drop movies with NaN synopsis\n",
    "    metadata = metadata.dropna()\n",
    "    metadata['tmdbId'] = metadata['tmdbId'].astype(float)\n",
    "    metadata = metadata.drop_duplicates(subset=['tmdbId'])\n",
    "\n",
    "        \n",
    "    # get only synopsis for movies in the transaction list\n",
    "    synopsis_set = seen_movies.merge(metadata, on='tmdbId', how='inner')\n",
    "    \n",
    "    # preprocess synopsis strings\n",
    "    synopsis_set['overview'] = synopsis_set['overview'].apply(preprocess_string)\n",
    "    \n",
    "    # TF-IDF processing\n",
    "    tfidfvectorizer = TfidfVectorizer(analyzer='word', token_pattern = '[a-z]+\\w*', stop_words='english', max_features=num_features)\n",
    "    tfidf_vector = tfidfvectorizer.fit_transform(synopsis_set['overview'])\n",
    "    tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=synopsis_set['movieId'], columns=tfidfvectorizer.get_feature_names_out())\n",
    "    \n",
    "    # normalization per column (word)\n",
    "    tfidf_df = tfidf_df.apply(lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "    tfidf_df = tfidf_df.reset_index()\n",
    "    \n",
    "    # rename cols\n",
    "    old_cols = tfidf_df.columns\n",
    "    new_cols = []\n",
    "    new_cols.append(old_cols[0])\n",
    "    for idx, col in enumerate(old_cols[1:], 1):\n",
    "        new_cols.append(f'i_{idx}')\n",
    "    tfidf_df.rename(columns=dict(zip(old_cols, new_cols)), inplace=True)\n",
    "    \n",
    "    return tfidf_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7844f8c3-f620-45ed-b4dd-6f8ac564946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feature_table = create_item_feature(num_features = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21ed7be-5c2e-461b-a521-3dd1b77c4813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>i_1</th>\n",
       "      <th>i_2</th>\n",
       "      <th>i_3</th>\n",
       "      <th>i_4</th>\n",
       "      <th>i_5</th>\n",
       "      <th>i_6</th>\n",
       "      <th>i_7</th>\n",
       "      <th>i_8</th>\n",
       "      <th>i_9</th>\n",
       "      <th>...</th>\n",
       "      <th>i_291</th>\n",
       "      <th>i_292</th>\n",
       "      <th>i_293</th>\n",
       "      <th>i_294</th>\n",
       "      <th>i_295</th>\n",
       "      <th>i_296</th>\n",
       "      <th>i_297</th>\n",
       "      <th>i_298</th>\n",
       "      <th>i_299</th>\n",
       "      <th>i_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  i_1  i_2  i_3  i_4  i_5  i_6  i_7  i_8       i_9  ...  i_291  \\\n",
       "0        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...    0.0   \n",
       "1        3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...    0.0   \n",
       "2        6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.513025  ...    0.0   \n",
       "3       47  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...    0.0   \n",
       "4       50  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...    0.0   \n",
       "\n",
       "   i_292  i_293  i_294  i_295  i_296  i_297  i_298  i_299  i_300  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feature_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3aaa8a-e069-4a81-b3b8-bd82fecdf32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9508, 301)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feature_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71a5a1-e522-4132-b68a-a4da50415d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
